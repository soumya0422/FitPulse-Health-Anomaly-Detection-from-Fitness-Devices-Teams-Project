{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pkill -f streamlit\n",
        "from pyngrok import ngrok\n",
        "ngrok.kill()"
      ],
      "metadata": {
        "id": "8P7HMJYtgU0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eWvSCfJRiLi5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9e8df6f-17f5-4b31-fb97-0e6d43da4651"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/78.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”\u001b[0m \u001b[32m71.7/78.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for typing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for Optional (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# ===================== INSTALL REQUIRED PACKAGES =====================\n",
        "!pip install fastapi uvicorn pyngrok pandas numpy prophet scikit-learn tsfresh matplotlib plotly streamlit requests openai typing Optional reportlab --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CCqiYAjEipQ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d2196db-9a52-4bf7-fa8e-4721d7f80d90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.set_auth_token(\"Auth_Token\")\n",
        "# ngrok.set_auth_token(\"380ZzaoDdXGvfjMya7VVYPbpJA4_3dcMEvWNppZQDdUGs9j7p\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"API_key\"\n",
        "!uvicorn backend:app --host 0.0.0.0 --port 8003"
      ],
      "metadata": {
        "id": "rlKUqqDT1KO5",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a67970bf-43f7-4e7c-b7ac-e8e9abf00356"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR\u001b[0m:    Error loading ASGI app. Could not import module \"backend\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile backend.py\n",
        "from fastapi import FastAPI, UploadFile, File\n",
        "from fastapi.responses import JSONResponse, FileResponse\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "import pandas as pd\n",
        "from prophet import Prophet\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import DBSCAN\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from reportlab.platypus import (\n",
        "    SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, Image\n",
        ")\n",
        "from reportlab.lib.styles import getSampleStyleSheet\n",
        "from reportlab.lib.pagesizes import A4\n",
        "from reportlab.lib import colors\n",
        "from datetime import datetime\n",
        "import glob\n",
        "from openai import OpenAI\n",
        "\n",
        "\n",
        "from fastapi import Body\n",
        "from typing import Optional\n",
        "\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "client = OpenAI(api_key=api_key) if api_key else None\n",
        "\n",
        "\n",
        "# ================= APP =================\n",
        "app = FastAPI(title=\"FitPulse Backend\")\n",
        "\n",
        "# ================= CORS =================\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "# ================= GLOBAL STATE =================\n",
        "CLEAN_DF = None\n",
        "FEATURE_DF = None\n",
        "ANOMALY_DF = None\n",
        "RULE_RECOMMENDATIONS = None\n",
        "\n",
        "# ================= ROOT =================\n",
        "def classify_severity(count: int):\n",
        "    if count >= 20:\n",
        "        return \"High\"\n",
        "    elif count >= 5:\n",
        "        return \"Medium\"\n",
        "    return \"Low\"\n",
        "\n",
        "def df_to_table(df, max_rows=10):\n",
        "    data = [df.columns.tolist()] + df.head(max_rows).values.tolist()\n",
        "    return Table(data, repeatRows=1)\n",
        "\n",
        "@app.get(\"/\")\n",
        "def root():\n",
        "    return {\"message\": \"FitPulse Backend is running\"}\n",
        "\n",
        "# ================= PREPROCESSING (CSV + JSON) =================\n",
        "@app.post(\"/preprocess\")\n",
        "async def preprocess(file: UploadFile = File(...)):\n",
        "    global CLEAN_DF\n",
        "\n",
        "    try:\n",
        "        if file.filename.endswith(\".csv\"):\n",
        "            df = pd.read_csv(file.file)\n",
        "        elif file.filename.endswith(\".json\"):\n",
        "            df = pd.read_json(file.file)\n",
        "        else:\n",
        "            return JSONResponse(status_code=400, content={\"error\": \"Only CSV or JSON supported\"})\n",
        "    except Exception as e:\n",
        "        return JSONResponse(status_code=400, content={\"error\": f\"Invalid file: {e}\"})\n",
        "\n",
        "    required_cols = [\"user_id\", \"date\", \"TotalSteps\", \"avg_heart_rate\", \"total_sleep_minutes\"]\n",
        "    missing = [c for c in required_cols if c not in df.columns]\n",
        "    if missing:\n",
        "        return JSONResponse(status_code=400, content={\"error\": f\"Missing columns: {missing}\"})\n",
        "\n",
        "    # ---------- CLEANING ----------\n",
        "    df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
        "    for col in [\"TotalSteps\", \"avg_heart_rate\", \"total_sleep_minutes\"]:\n",
        "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "\n",
        "    df[\"TotalSteps\"].fillna(0, inplace=True)\n",
        "    df[\"avg_heart_rate\"].fillna(df[\"avg_heart_rate\"].median(), inplace=True)\n",
        "    df[\"total_sleep_minutes\"].fillna(df[\"total_sleep_minutes\"].median(), inplace=True)\n",
        "\n",
        "    # ---------- AGGREGATE ----------\n",
        "    df = df.groupby([\"user_id\", \"date\"], as_index=False).agg({\n",
        "        \"TotalSteps\": \"sum\",\n",
        "        \"avg_heart_rate\": \"mean\",\n",
        "        \"total_sleep_minutes\": \"mean\"\n",
        "    })\n",
        "\n",
        "    # ---------- RENAME FOR UI ----------\n",
        "    df.rename(columns={\n",
        "        \"avg_heart_rate\": \"heart_rate\",\n",
        "        \"TotalSteps\": \"steps\",\n",
        "        \"total_sleep_minutes\": \"sleep\"\n",
        "    }, inplace=True)\n",
        "\n",
        "    # Convert sleep minutes â†’ hours (matches screenshot ~7.05)\n",
        "    df[\"sleep\"] = (df[\"sleep\"] / 60).round(2)\n",
        "\n",
        "    CLEAN_DF = df\n",
        "    df.to_csv(\"clean_data.csv\", index=False)\n",
        "\n",
        "\n",
        "    return {\n",
        "        \"status\": \"success\",\n",
        "        \"overview\": {\n",
        "            \"rows_loaded\": len(df),\n",
        "            \"users\": df[\"user_id\"].nunique(),\n",
        "            \"days\": df[\"date\"].nunique(),\n",
        "            \"avg_hr\": round(df[\"heart_rate\"].mean(), 1)\n",
        "        },\n",
        "        \"preview\": df.head(20).to_dict(orient=\"records\")\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "# ================= OVERVIEW =================\n",
        "@app.get(\"/overview\")\n",
        "def overview():\n",
        "    if CLEAN_DF is None:\n",
        "        return {\"error\": \"Run /preprocess first\"}\n",
        "    df = CLEAN_DF\n",
        "    return {\n",
        "        \"rows\": len(df),\n",
        "        \"users_count\": df[\"user_id\"].nunique(),\n",
        "        \"users_list\": df[\"user_id\"].astype(str).unique().tolist(),  # <-- add this\n",
        "        \"start_date\": str(df[\"date\"].min().date()),\n",
        "        \"end_date\": str(df[\"date\"].max().date()),\n",
        "        \"avg_heart_rate\": round(df[\"heart_rate\"].mean(), 2),\n",
        "        \"avg_steps\": round(df[\"steps\"].mean(), 2),\n",
        "        \"avg_sleep_hours\": round(df[\"sleep\"].mean(), 2),\n",
        "    }\n",
        "\n",
        "# ================= FEATURES + ANOMALIES =================\n",
        "@app.post(\"/module2\")\n",
        "def module2():\n",
        "    global FEATURE_DF, ANOMALY_DF, RULE_RECOMMENDATIONS\n",
        "    if CLEAN_DF is None:\n",
        "        return JSONResponse(status_code=400, content={\"error\": \"Run /preprocess first\"})\n",
        "\n",
        "    df = CLEAN_DF.copy().sort_values(\"date\")\n",
        "\n",
        "\n",
        "    FEATURE_DF = df.copy()\n",
        "\n",
        "    # Rolling 7-day mean features\n",
        "    for col in [\"steps\", \"heart_rate\", \"sleep\"]:\n",
        "        FEATURE_DF[f\"{col}_mean_7\"] = FEATURE_DF[col].rolling(7).mean()\n",
        "        FEATURE_DF[f\"{col}_std_7\"] = FEATURE_DF[col].rolling(7).std()\n",
        "        FEATURE_DF[f\"{col}_skew_7\"] = FEATURE_DF[col].rolling(7).skew()\n",
        "        FEATURE_DF[f\"{col}_kurt_7\"] = FEATURE_DF[col].rolling(7).kurt()\n",
        "\n",
        "    FEATURE_DF.to_csv(\"feature_data.csv\", index=False)\n",
        "\n",
        "    # Rule-based anomalies\n",
        "    records = []\n",
        "    for _, r in df.iterrows():\n",
        "        if r[\"heart_rate\"] > 120: records.append((r[\"user_id\"], r[\"date\"], \"heart_rate_high\"))\n",
        "        if r[\"heart_rate\"] < 40: records.append((r[\"user_id\"], r[\"date\"], \"heart_rate_low\"))\n",
        "        if r[\"steps\"] == 0: records.append((r[\"user_id\"], r[\"date\"], \"no_steps\"))\n",
        "        if r[\"sleep\"] < 4 or r[\"sleep\"] > 12: records.append((r[\"user_id\"], r[\"date\"], \"sleep_abnormal\"))\n",
        "\n",
        "    rule_df = pd.DataFrame(records, columns=[\"user_id\", \"date\", \"metric\"])\n",
        "\n",
        "    # DBSCAN anomalies\n",
        "    X_scaled = StandardScaler().fit_transform(df[[\"heart_rate\", \"steps\", \"sleep\"]])\n",
        "    labels = DBSCAN(eps=1.2, min_samples=3).fit_predict(X_scaled)\n",
        "    df[\"cluster\"] = labels\n",
        "    dbscan_df = df[df[\"cluster\"] == -1][[\"user_id\", \"date\"]].copy()\n",
        "    dbscan_df[\"metric\"] = \"dbscan_outlier\"\n",
        "\n",
        "    ANOMALY_DF = pd.concat([rule_df, dbscan_df], ignore_index=True)\n",
        "\n",
        "    summary_df = (\n",
        "        ANOMALY_DF\n",
        "        .groupby([\"user_id\", \"metric\"])\n",
        "        .size()\n",
        "        .reset_index(name=\"count\")\n",
        "    )\n",
        "\n",
        "    summary_df[\"severity\"] = summary_df[\"count\"].apply(classify_severity)\n",
        "\n",
        "    # Save both versions\n",
        "    ANOMALY_DF.to_csv(\"anomaly_raw.csv\", index=False)\n",
        "    summary_df.to_csv(\"anomaly_report.csv\", index=False)\n",
        "\n",
        "\n",
        "    recs = []\n",
        "\n",
        "    for _, row in summary_df.iterrows():\n",
        "        user = row[\"user_id\"]\n",
        "        metric = row[\"metric\"]\n",
        "        severity = row[\"severity\"]\n",
        "\n",
        "        if metric == \"heart_rate_high\":\n",
        "            recs.append({\n",
        "                \"user_id\": user,\n",
        "                \"issue\": \"High heart rate\",\n",
        "                \"severity\": severity,\n",
        "                \"recommendation\": \"Reduce high-intensity workouts and consult a physician if persistent.\"\n",
        "            })\n",
        "\n",
        "        elif metric == \"heart_rate_low\":\n",
        "            recs.append({\n",
        "                \"user_id\": user,\n",
        "                \"issue\": \"Low heart rate\",\n",
        "                \"severity\": severity,\n",
        "                \"recommendation\": \"Ensure adequate nutrition and consult a healthcare professional.\"\n",
        "            })\n",
        "\n",
        "        elif metric == \"no_steps\":\n",
        "            recs.append({\n",
        "                \"user_id\": user,\n",
        "                \"issue\": \"No physical activity\",\n",
        "                \"severity\": severity,\n",
        "                \"recommendation\": \"Increase daily movement with light walks or stretching.\"\n",
        "            })\n",
        "\n",
        "        elif metric == \"sleep_abnormal\":\n",
        "            recs.append({\n",
        "                \"user_id\": user,\n",
        "                \"issue\": \"Abnormal sleep duration\",\n",
        "                \"severity\": severity,\n",
        "                \"recommendation\": \"Maintain a consistent sleep schedule and improve sleep hygiene.\"\n",
        "            })\n",
        "\n",
        "        elif metric == \"dbscan_outlier\":\n",
        "            recs.append({\n",
        "                \"user_id\": user,\n",
        "                \"issue\": \"Unusual health pattern\",\n",
        "                \"severity\": severity,\n",
        "                \"recommendation\": \"Monitor trends closely; consider lifestyle adjustments.\"\n",
        "            })\n",
        "\n",
        "    RULE_RECOMMENDATIONS = pd.DataFrame(recs)\n",
        "    RULE_RECOMMENDATIONS.to_csv(\"recommendations.csv\", index=False)\n",
        "\n",
        "    return {\n",
        "        \"status\": \"success\",\n",
        "        \"total_anomalies\": len(ANOMALY_DF),\n",
        "        \"summary_rows\": len(summary_df)\n",
        "    }\n",
        "\n",
        "\n",
        "# ================= ANOMALY SUMMARY =================\n",
        "\n",
        "@app.get(\"/module3/summary\")\n",
        "def anomaly_summary(user_id: str = \"All\"):\n",
        "    if ANOMALY_DF is None or ANOMALY_DF.empty:\n",
        "        return {\"summary\": {}}\n",
        "\n",
        "    df = ANOMALY_DF.copy()\n",
        "    df[\"user_id\"] = df[\"user_id\"].astype(str)\n",
        "\n",
        "    if user_id != \"All\":\n",
        "        df = df[df[\"user_id\"] == user_id]\n",
        "\n",
        "    return {\"summary\": df[\"metric\"].value_counts().to_dict()}\n",
        "\n",
        "\n",
        "# ================= PROPHET PLOTS =================\n",
        "def plot_prophet(df, column, fname, ylabel):\n",
        "    df2 = df[[\"date\", column]].rename(columns={\"date\":\"ds\", column:\"y\"})\n",
        "    if len(df2) < 10: return None\n",
        "    model = Prophet()\n",
        "    model.fit(df2)\n",
        "    forecast = model.predict(df2)\n",
        "    df2[\"yhat\"] = forecast[\"yhat\"]\n",
        "    df2[\"residual\"] = df2[\"y\"] - df2[\"yhat\"]\n",
        "    threshold = 2.5 * df2[\"residual\"].std()\n",
        "    outliers = df2[abs(df2[\"residual\"]) > threshold]\n",
        "\n",
        "    plt.figure(figsize=(12,5))\n",
        "    plt.plot(df2[\"ds\"], df2[\"y\"], label=f\"Actual {ylabel}\",color=\"blue\")\n",
        "    plt.plot(df2[\"ds\"], df2[\"yhat\"], label=\"Prophet Trend\",color=\"red\")\n",
        "    plt.scatter(outliers[\"ds\"], outliers[\"y\"], color=\"red\", label=\"Anomaly\")\n",
        "    plt.xlabel(\"Date\")\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.title(f\"{ylabel} Prophet Trend Anomalies\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(fname)\n",
        "    plt.close()\n",
        "    return fname\n",
        "@app.get(\"/module3/anomaly-table\")\n",
        "def anomaly_table():\n",
        "    if not os.path.exists(\"anomaly_report.csv\"):\n",
        "        return JSONResponse(status_code=404, content={\"error\": \"Run anomaly detection first\"})\n",
        "\n",
        "    df = pd.read_csv(\"anomaly_report.csv\")\n",
        "    return {\n",
        "        \"rows\": df.to_dict(orient=\"records\")\n",
        "    }\n",
        "@app.get(\"/module3/prophet/{metric}\")\n",
        "def prophet_metric(metric: str, user_id: str = \"All\"):\n",
        "    mapping = {\n",
        "        \"heart_rate\": \"Heart Rate (BPM)\",\n",
        "        \"steps\": \"Steps\",\n",
        "        \"sleep\": \"Sleep (Hours)\"\n",
        "    }\n",
        "\n",
        "    if FEATURE_DF is None:\n",
        "        return JSONResponse(status_code=400, content={\"error\": \"Run /module2 first\"})\n",
        "\n",
        "    if metric not in mapping:\n",
        "        return JSONResponse(status_code=400, content={\"error\": \"Invalid metric\"})\n",
        "\n",
        "    # âœ… FORCE STRING TYPES (THIS IS THE KEY FIX)\n",
        "    df = FEATURE_DF.copy()\n",
        "    df[\"user_id\"] = df[\"user_id\"].astype(str)\n",
        "    user_id = str(user_id)\n",
        "\n",
        "    # âœ… APPLY USER FILTER\n",
        "    if user_id != \"All\":\n",
        "        df = df[df[\"user_id\"] == user_id]\n",
        "\n",
        "    if df.empty:\n",
        "        return JSONResponse(status_code=400, content={\"error\": \"No data for selected user\"})\n",
        "\n",
        "    fname = f\"prophet_{metric}.png\"\n",
        "\n",
        "    # âœ… PASS FILTERED DATA ONLY\n",
        "    if plot_prophet(df, metric, fname, mapping[metric]):\n",
        "        return FileResponse(fname)\n",
        "\n",
        "    return JSONResponse(status_code=400, content={\"error\": \"Not enough data\"})\n",
        "\n",
        "\n",
        "\n",
        "# ================= DBSCAN VISUALIZATION =================\n",
        "# ================= DBSCAN VISUALIZATION =================\n",
        "@app.get(\"/module3/dbscan\")\n",
        "def dbscan_viz(user_id: str = \"All\"):\n",
        "    if FEATURE_DF is None:\n",
        "        return JSONResponse(status_code=400, content={\"error\": \"Run /module2 first\"})\n",
        "\n",
        "    df = FEATURE_DF.copy()\n",
        "    df[\"user_id\"] = df[\"user_id\"].astype(str)\n",
        "\n",
        "    if user_id != \"All\":\n",
        "        df = df[df[\"user_id\"] == user_id]\n",
        "\n",
        "    if df.empty:\n",
        "        return JSONResponse(status_code=400, content={\"error\": \"No data for selected user\"})\n",
        "\n",
        "    X_scaled = StandardScaler().fit_transform(df[[\"heart_rate\", \"steps\", \"sleep\"]])\n",
        "    labels = DBSCAN(eps=1.2, min_samples=3).fit_predict(X_scaled)\n",
        "    df[\"cluster\"] = labels\n",
        "\n",
        "    normal = df[df[\"cluster\"] != -1]\n",
        "    outliers = df[df[\"cluster\"] == -1]\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.scatter(normal[\"steps\"], normal[\"heart_rate\"], label=\"Normal\", alpha=0.6)\n",
        "    plt.scatter(outliers[\"steps\"], outliers[\"heart_rate\"], label=\"Outlier\", alpha=0.9)\n",
        "\n",
        "    plt.xlabel(\"Steps\")\n",
        "    plt.ylabel(\"Heart Rate\")\n",
        "    plt.title(\"DBSCAN Clustering\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    fname = \"dbscan.png\"\n",
        "    plt.savefig(fname)\n",
        "    plt.close()\n",
        "\n",
        "    return FileResponse(fname)\n",
        "\n",
        "\n",
        "# ================= DISTRIBUTION =================\n",
        "# ================= DISTRIBUTION =================\n",
        "@app.get(\"/module3/distribution/{metric}\")\n",
        "def distribution(metric: str, user_id: str = \"All\"):\n",
        "    if FEATURE_DF is None:\n",
        "        return JSONResponse(status_code=400, content={\"error\": \"Run /module2 first\"})\n",
        "\n",
        "    if metric not in [\"heart_rate\", \"steps\", \"sleep\"]:\n",
        "        return JSONResponse(status_code=400, content={\"error\": \"Invalid metric\"})\n",
        "\n",
        "    df = FEATURE_DF.copy()\n",
        "    df[\"user_id\"] = df[\"user_id\"].astype(str)\n",
        "\n",
        "    if user_id != \"All\":\n",
        "        df = df[df[\"user_id\"] == user_id]\n",
        "\n",
        "    if df.empty:\n",
        "        return JSONResponse(status_code=400, content={\"error\": \"No data for selected user\"})\n",
        "\n",
        "    colors_map = {\n",
        "        \"heart_rate\": \"crimson\",\n",
        "        \"steps\": \"royalblue\",\n",
        "        \"sleep\": \"green\"\n",
        "    }\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.hist(df[metric], bins=20, color=colors_map[metric], edgecolor=\"black\")\n",
        "    plt.xlabel(metric)\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.title(f\"{metric} Distribution\")\n",
        "    plt.grid(True)\n",
        "\n",
        "    fname = f\"{metric}_dist.png\"\n",
        "    plt.savefig(fname)\n",
        "    plt.close()\n",
        "\n",
        "    return FileResponse(fname)\n",
        "\n",
        "\n",
        "@app.get(\"/recommendations\")\n",
        "def get_recommendations(user_id: str = \"All\"):\n",
        "    if RULE_RECOMMENDATIONS is None or RULE_RECOMMENDATIONS.empty:\n",
        "        return {\"message\": \"No rule-based recommendations available\"}\n",
        "\n",
        "    df = RULE_RECOMMENDATIONS.copy()\n",
        "    df[\"user_id\"] = df[\"user_id\"].astype(str)\n",
        "\n",
        "    if user_id != \"All\":\n",
        "        df = df[df[\"user_id\"] == user_id]\n",
        "\n",
        "    return df.to_dict(orient=\"records\")\n",
        "\n",
        "\n",
        "# ================= DOWNLOAD ANOMALIES =================\n",
        "@app.get(\"/download-anomalies\")\n",
        "def download_anomalies():\n",
        "    if not os.path.exists(\"anomaly_report.csv\"):\n",
        "        return JSONResponse(status_code=404, content={\"error\": \"No anomalies\"})\n",
        "\n",
        "    return FileResponse(\n",
        "        \"anomaly_report.csv\",\n",
        "        media_type=\"text/csv\",\n",
        "        filename=\"anomaly_report.csv\"\n",
        "    )\n",
        "@app.get(\"/download-report\")\n",
        "def download_report():\n",
        "    if CLEAN_DF is None:\n",
        "        return JSONResponse(status_code=400, content={\"error\": \"Run preprocess first\"})\n",
        "\n",
        "    filename = \"fitpulse_dashboard_report.pdf\"\n",
        "    doc = SimpleDocTemplate(filename, pagesize=A4)\n",
        "    styles = getSampleStyleSheet()\n",
        "    story = []\n",
        "\n",
        "    # ---------- TITLE ----------\n",
        "    story.append(Paragraph(\"<b>FitPulse Health Analytics Report</b>\", styles[\"Title\"]))\n",
        "    story.append(Spacer(1, 12))\n",
        "    story.append(Paragraph(\n",
        "        f\"Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\",\n",
        "        styles[\"Normal\"]\n",
        "    ))\n",
        "    story.append(Spacer(1, 20))\n",
        "\n",
        "    # ---------- OVERVIEW ----------\n",
        "    df = CLEAN_DF.copy()\n",
        "    overview_data = [\n",
        "        [\"Metric\", \"Value\"],\n",
        "        [\"Rows Loaded\", len(df)],\n",
        "        [\"Users\", df[\"user_id\"].nunique()],\n",
        "        [\"Days\", df[\"date\"].nunique()],\n",
        "        [\"Avg Heart Rate\", round(df[\"heart_rate\"].mean(), 1)],\n",
        "        [\"Start Date\", str(df[\"date\"].min().date())],\n",
        "        [\"End Date\", str(df[\"date\"].max().date())],\n",
        "    ]\n",
        "\n",
        "    overview_table = Table(overview_data)\n",
        "    overview_table.setStyle(TableStyle([\n",
        "        (\"BACKGROUND\", (0,0), (-1,0), colors.lightgrey),\n",
        "        (\"GRID\", (0,0), (-1,-1), 1, colors.black),\n",
        "        (\"FONT\", (0,0), (-1,0), \"Helvetica-Bold\"),\n",
        "    ]))\n",
        "\n",
        "    story.append(Paragraph(\"<b>Dataset Overview</b>\", styles[\"Heading2\"]))\n",
        "    story.append(Spacer(1, 10))\n",
        "    story.append(overview_table)\n",
        "    story.append(Spacer(1, 20))\n",
        "\n",
        "    # ---------- SAMPLE DATA ----------\n",
        "    story.append(Paragraph(\"<b>Sample Records</b>\", styles[\"Heading2\"]))\n",
        "    sample_table = df_to_table(df)\n",
        "    sample_table.setStyle(TableStyle([\n",
        "        (\"GRID\", (0,0), (-1,-1), 0.5, colors.grey),\n",
        "        (\"BACKGROUND\", (0,0), (-1,0), colors.whitesmoke),\n",
        "    ]))\n",
        "    story.append(sample_table)\n",
        "    story.append(Spacer(1, 20))\n",
        "\n",
        "    # ---------- ANOMALY SUMMARY ----------\n",
        "    if os.path.exists(\"anomaly_report.csv\"):\n",
        "        anom_df = pd.read_csv(\"anomaly_report.csv\")\n",
        "        story.append(Paragraph(\"<b>Anomaly Summary</b>\", styles[\"Heading2\"]))\n",
        "        anom_table = df_to_table(anom_df)\n",
        "        anom_table.setStyle(TableStyle([\n",
        "            (\"GRID\", (0,0), (-1,-1), 0.5, colors.grey),\n",
        "            (\"BACKGROUND\", (0,0), (-1,0), colors.lightgrey),\n",
        "        ]))\n",
        "        story.append(anom_table)\n",
        "        story.append(Spacer(1, 20))\n",
        "\n",
        "    # ---------- IMAGES ----------\n",
        "    story.append(Paragraph(\"<b>Visual Analytics</b>\", styles[\"Heading2\"]))\n",
        "    story.append(Spacer(1, 10))\n",
        "\n",
        "    image_files = (\n",
        "      glob.glob(\"prophet_heart_rate_*.png\") +\n",
        "      glob.glob(\"prophet_steps_*.png\") +\n",
        "      glob.glob(\"prophet_sleep_*.png\") +\n",
        "      [\"dbscan.png\", \"heart_rate_dist.png\", \"steps_dist.png\", \"sleep_dist.png\"]\n",
        "    )\n",
        "\n",
        "\n",
        "    for img in image_files:\n",
        "        if os.path.exists(img):\n",
        "            story.append(Image(img, width=400, height=220))\n",
        "            story.append(Spacer(1, 12))\n",
        "\n",
        "    # ---------- BUILD ----------\n",
        "    # ---------- RECOMMENDATIONS ----------\n",
        "    if os.path.exists(\"recommendations.csv\"):\n",
        "        rec_df = pd.read_csv(\"recommendations.csv\")\n",
        "        story.append(Paragraph(\"<b>Health Recommendations</b>\", styles[\"Heading2\"]))\n",
        "        rec_table = df_to_table(rec_df)\n",
        "        rec_table.setStyle(TableStyle([\n",
        "            (\"GRID\", (0,0), (-1,-1), 0.5, colors.grey),\n",
        "            (\"BACKGROUND\", (0,0), (-1,0), colors.lightgrey),\n",
        "        ]))\n",
        "        story.append(rec_table)\n",
        "        story.append(Spacer(1, 20))\n",
        "\n",
        "    doc.build(story)\n",
        "\n",
        "    return FileResponse(\n",
        "        filename,\n",
        "        media_type=\"application/pdf\",\n",
        "        filename=filename\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "@app.post(\"/llm-advice\")\n",
        "def llm_advice(\n",
        "    question: str = Body(...),\n",
        "    user_id: Optional[str] = Body(\"All\")\n",
        "):\n",
        "    if client is None:\n",
        "        return JSONResponse(\n",
        "            status_code=500,\n",
        "            content={\"error\": \"LLM not configured. OPENAI_API_KEY missing.\"}\n",
        "        )\n",
        "\n",
        "    try:\n",
        "        ...\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You provide general wellness advice, not medical diagnosis.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            temperature=0.4,\n",
        "            max_tokens=300\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"answer\": response.choices[0].message.content.strip(),\n",
        "            \"user_id\": user_id\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        return JSONResponse(\n",
        "            status_code=500,\n",
        "            content={\"error\": f\"LLM error: {str(e)}\"}\n",
        "        )\n"
      ],
      "metadata": {
        "id": "I14jE5jjv7W5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50b30a66-ebcb-4114-e721-13108b3dc9bc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing backend.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "yUa7Fy5Yi63o"
      },
      "outputs": [],
      "source": [
        "import threading\n",
        "import uvicorn\n",
        "\n",
        "def run_backend():\n",
        "    uvicorn.run(\"backend:app\", host=\"0.0.0.0\", port=8003)\n",
        "\n",
        "threading.Thread(target=run_backend).start()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "backend_url = ngrok.connect(8003)\n",
        "print(\"BACKEND URL:\", backend_url)"
      ],
      "metadata": {
        "id": "ZsKGrZo9jJSb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "196357e3-a460-4d26-ef4b-2d3295e3a3c9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BACKEND URL: NgrokTunnel: \"https://renowned-zuri-coleopterous.ngrok-free.dev\" -> \"http://localhost:8003\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p .streamlit"
      ],
      "metadata": {
        "id": "zVLzc69wlzqt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile .streamlit/config.toml\n",
        "[theme]\n",
        "base=\"light\"\n",
        "primaryColor=\"#E63946\"\n",
        "backgroundColor=\"#F1FAEE\"\n",
        "secondaryBackgroundColor=\"#A8DADC\"\n",
        "textColor=\"#1D3557\""
      ],
      "metadata": {
        "id": "AibKm3_XmA3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18a13254-a960-4471-e105-c7e7f1ac1701"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing .streamlit/config.toml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import requests\n",
        "import io\n",
        "from datetime import datetime\n",
        "import plotly.express as px\n",
        "\n",
        "# ================= CONFIG =================\n",
        "BACKEND = \"http://localhost:8003\"\n",
        "HEADERS = {\"ngrok-skip-browser-warning\": \"true\"}\n",
        "\n",
        "st.set_page_config(\n",
        "    page_title=\"FitPulse Health Analytics\",\n",
        "    layout=\"wide\"\n",
        ")\n",
        "\n",
        "# ================= SESSION STATE =================\n",
        "if \"preprocess_done\" not in st.session_state:\n",
        "    st.session_state.preprocess_done = False\n",
        "\n",
        "if \"module2_done\" not in st.session_state:\n",
        "    st.session_state.module2_done = False\n",
        "\n",
        "# ================= API HELPERS =================\n",
        "def api_get(endpoint, raw=False):\n",
        "    r = requests.get(f\"{BACKEND}{endpoint}\", headers=HEADERS)\n",
        "    return r if raw else r.json()\n",
        "\n",
        "def api_post(endpoint, files=None):\n",
        "    return requests.post(f\"{BACKEND}{endpoint}\", files=files, headers=HEADERS).json()\n",
        "\n",
        "def api_post_json(endpoint, payload=None):\n",
        "    r = requests.post(f\"{BACKEND}{endpoint}\", json=payload, headers=HEADERS)\n",
        "\n",
        "    if r.status_code != 200:\n",
        "        st.error(f\"Backend error {r.status_code}\")\n",
        "        st.text(r.text)\n",
        "        return {}\n",
        "\n",
        "    try:\n",
        "        return r.json()\n",
        "    except Exception:\n",
        "        st.error(\"Backend did not return JSON\")\n",
        "        st.text(r.text)\n",
        "        return {}\n",
        "\n",
        "\n",
        "\n",
        "# ================= COMMON FILTERS =================\n",
        "def sidebar_filters(metrics=True):\n",
        "    overview = api_get(\"/overview\")\n",
        "    users = [\"All\"]\n",
        "\n",
        "    try:\n",
        "        backend_users = overview.get(\"users_list\", [])\n",
        "        users += sorted([str(u) for u in backend_users])\n",
        "\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    user = st.sidebar.selectbox(\"Select User\", users)\n",
        "\n",
        "    try:\n",
        "        start = datetime.strptime(overview[\"start_date\"], \"%Y-%m-%d\")\n",
        "        end = datetime.strptime(overview[\"end_date\"], \"%Y-%m-%d\")\n",
        "    except:\n",
        "        start, end = datetime.today(), datetime.today()\n",
        "\n",
        "    dates = st.sidebar.date_input(\"Date Range\", [start, end])\n",
        "\n",
        "    metric = None\n",
        "    if metrics:\n",
        "        metric = st.sidebar.multiselect(\n",
        "            \"Select Metrics\",\n",
        "            [\"heart_rate\", \"steps\", \"sleep\"],\n",
        "            default=[\"heart_rate\", \"steps\", \"sleep\"]\n",
        "        )\n",
        "\n",
        "    return user, dates, metric\n",
        "\n",
        "# ================= SIDEBAR =================\n",
        "st.sidebar.title(\"FitPulse Controls\")\n",
        "\n",
        "page = st.sidebar.radio(\n",
        "    \"Navigation\",\n",
        "    [\n",
        "        \"1. Data Upload & Preprocessing\",\n",
        "        \"2. Feature Engineering & Anomalies\",\n",
        "        \"3. Trends\",\n",
        "        \"4. Anomalies\",\n",
        "        \"5. Distributions & DBSCAN\",\n",
        "        \"6. Downloads\"\n",
        "    ]\n",
        ")\n",
        "\n",
        "st.sidebar.divider()\n",
        "\n",
        "# ================= PAGE ROUTER =================\n",
        "if page == \"1. Data Upload & Preprocessing\":\n",
        "    st.title(\"FitPulse Health Analytics\")\n",
        "    with st.expander(\"Project Overview\", expanded=True):\n",
        "        st.markdown(\"\"\"\n",
        "**FitPulse** is an end-to-end health analytics system for wearable data.\n",
        "\n",
        "**Input Columns**\n",
        "- user_id\n",
        "- date\n",
        "- TotalSteps\n",
        "- avg_heart_rate\n",
        "- total_sleep_minutes\n",
        "\n",
        "**Outputs**\n",
        "- Cleaned dataset\n",
        "- Rolling health features\n",
        "- Anomalies & clustering\n",
        "- Interactive trends\n",
        "- CSV & PDF reports\n",
        "        \"\"\")\n",
        "\n",
        "    uploaded = st.file_uploader(\"Upload file\", type=[\"csv\", \"json\"])\n",
        "    if st.button(\"Run Preprocessing\"):\n",
        "        if not uploaded:\n",
        "            st.warning(\"Please upload a file first\")\n",
        "        else:\n",
        "            res = api_post(\"/preprocess\", files={\"file\": uploaded})\n",
        "            if res.get(\"status\") == \"success\":\n",
        "                st.success(\"Preprocessing completed\")\n",
        "                st.session_state.preprocess_done = True\n",
        "\n",
        "                ov = res[\"overview\"]\n",
        "                c1, c2, c3, c4 = st.columns(4)\n",
        "                c1.metric(\"Records\", ov[\"rows_loaded\"])\n",
        "                c2.metric(\"Users\", ov[\"users\"])\n",
        "                c3.metric(\"Days\", ov[\"days\"])\n",
        "                c4.metric(\"Avg HR\", ov[\"avg_hr\"])\n",
        "\n",
        "                st.dataframe(pd.DataFrame(res[\"preview\"]), use_container_width=True)\n",
        "            else:\n",
        "                st.error(res)\n",
        "\n",
        "elif page == \"2. Feature Engineering & Anomalies\":\n",
        "    st.title(\"Feature Engineering & Anomaly Detection\")\n",
        "    if not st.session_state.preprocess_done:\n",
        "        st.warning(\"Complete preprocessing first\")\n",
        "    else:\n",
        "        if st.button(\"Run Feature Engineering & Anomaly Detection\"):\n",
        "            res = api_post(\"/module2\")\n",
        "            if res.get(\"status\") == \"success\":\n",
        "                st.success(\"Module completed\")\n",
        "                st.session_state.module2_done = True\n",
        "                st.table(pd.DataFrame({\n",
        "                    \"Total Anomalies\": [res[\"total_anomalies\"]],\n",
        "                    \"Summary Rows\": [res[\"summary_rows\"]]\n",
        "                }))\n",
        "            else:\n",
        "                st.error(res)\n",
        "\n",
        "elif page == \"3. Trends\":\n",
        "    if not st.session_state.module2_done:\n",
        "        st.warning(\"Complete previous modules first\")\n",
        "    else:\n",
        "        st.title(\"Health Trends\")\n",
        "        user, _, metrics = sidebar_filters(metrics=True)\n",
        "\n",
        "        if not metrics:\n",
        "            st.warning(\"Select at least one metric\")\n",
        "        else:\n",
        "            for metric in metrics:\n",
        "                r = api_get(f\"/module3/prophet/{metric}?user_id={user}\", raw=True)\n",
        "                if r.status_code == 200:\n",
        "                    st.image(io.BytesIO(r.content), use_column_width=True)\n",
        "                else:\n",
        "                    st.error(r.json().get(\"error\", \"No data\"))\n",
        "\n",
        "elif page == \"4. Anomalies\":\n",
        "    if not st.session_state.module2_done:\n",
        "        st.warning(\"Complete previous modules first\")\n",
        "    else:\n",
        "        st.title(\"Anomaly Analysis\")\n",
        "        user, _, metrics = sidebar_filters(metrics=True)\n",
        "\n",
        "        summary = api_get(f\"/module3/summary?user_id={user}\")\n",
        "        df = pd.DataFrame(summary[\"summary\"].items(), columns=[\"Metric\", \"Count\"])\n",
        "\n",
        "        # ðŸ”¹ MAP UI METRICS â†’ BACKEND METRICS\n",
        "        metric_map = {\n",
        "            \"heart_rate\": [\"heart_rate_high\", \"heart_rate_low\"],\n",
        "            \"steps\": [\"no_steps\"],\n",
        "            \"sleep\": [\"sleep_abnormal\"]\n",
        "        }\n",
        "\n",
        "        selected_metrics = []\n",
        "        if metrics:\n",
        "            for m in metrics:\n",
        "                selected_metrics.extend(metric_map.get(m, []))\n",
        "\n",
        "        # FILTER SUMMARY\n",
        "        if selected_metrics:\n",
        "            df = df[df[\"Metric\"].isin(selected_metrics)]\n",
        "\n",
        "        fig = px.bar(df, x=\"Metric\", y=\"Count\", color=\"Metric\")\n",
        "        st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "        # ================= TABLE =================\n",
        "        table = api_get(\"/module3/anomaly-table\")\n",
        "        df_anom = pd.DataFrame(table[\"rows\"])\n",
        "\n",
        "        # ðŸ”¹ FIX USER TYPE MISMATCH\n",
        "        df_anom[\"user_id\"] = df_anom[\"user_id\"].astype(str)\n",
        "\n",
        "        if user != \"All\":\n",
        "            df_anom = df_anom[df_anom[\"user_id\"] == str(user)]\n",
        "\n",
        "        # FILTER TABLE BY METRICS\n",
        "        if selected_metrics:\n",
        "            df_anom = df_anom[df_anom[\"metric\"].isin(selected_metrics)]\n",
        "\n",
        "        st.dataframe(df_anom, use_container_width=True)\n",
        "\n",
        "elif page == \"5. Distributions & DBSCAN\":\n",
        "    if not st.session_state.module2_done:\n",
        "        st.warning(\"Complete previous modules first\")\n",
        "    else:\n",
        "        st.title(\"Distributions & Clustering\")\n",
        "        user, _, metrics = sidebar_filters(metrics=True)\n",
        "\n",
        "        for metric in metrics:\n",
        "            r = api_get(f\"/module3/distribution/{metric}?user_id={user}\", raw=True)\n",
        "            if r.status_code == 200:\n",
        "                st.image(io.BytesIO(r.content), caption=f\"{metric} distribution\", use_column_width=True)\n",
        "\n",
        "        if any(m in metrics for m in [\"heart_rate\", \"steps\", \"sleep\"]):\n",
        "            r = api_get(f\"/module3/dbscan?user_id={user}\", raw=True)\n",
        "            if r.status_code == 200:\n",
        "                st.image(io.BytesIO(r.content), caption=\"DBSCAN clustering\", use_column_width=True)\n",
        "\n",
        "elif page == \"6. Downloads\":\n",
        "    if not st.session_state.module2_done:\n",
        "        st.warning(\"Complete previous modules first\")\n",
        "    else:\n",
        "        st.title(\"Download Reports\")\n",
        "        user, _, _ = sidebar_filters(metrics=False)\n",
        "\n",
        "        r = api_get(\"/download-anomalies\", raw=True)\n",
        "        if r.status_code == 200:\n",
        "            st.download_button(\"Download Anomaly CSV\", r.content, \"anomaly_report.csv\")\n",
        "\n",
        "        r = api_get(\"/download-report\", raw=True)\n",
        "        if r.status_code == 200:\n",
        "            st.download_button(\"Download Full PDF Report\", r.content, \"fitpulse_dashboard_report.pdf\")\n",
        "\n",
        "        st.subheader(\"Ask Health Advisor (AI)\")\n",
        "        question = st.text_input(\"Ask a health-related question\")\n",
        "\n",
        "        if st.button(\"Ask AI\"):\n",
        "            res = api_post_json(\"/llm-advice\", {\"question\": question, \"user_id\": user})\n",
        "\n",
        "            if \"answer\" in res:\n",
        "                st.markdown(res[\"answer\"])\n",
        "            else:\n",
        "                st.error(res)\n",
        "\n",
        "st.caption(\"FitPulse | FastAPI Backend with Streamlit Frontend\")"
      ],
      "metadata": {
        "id": "-jNGlnLYOmxw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3de49196-02d3-4bbc-e664-121b085311e2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py --server.port 8501 --server.address 0.0.0.0"
      ],
      "metadata": {
        "id": "z6Bz5WMJjOIu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82762d3d-b804-418f-9fee-4d17be07c4d4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  URL: \u001b[0m\u001b[1mhttp://0.0.0.0:8501\u001b[0m\n",
            "\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2026-01-22T04:15:33+0000 lvl=warn msg=\"Stopping forwarder\" name=http-8003-f36bc27d-9bfa-4906-a52f-f774a0bf99c6 acceptErr=\"failed to accept connection: Listener closed\"\n",
            "WARNING:pyngrok.process.ngrok:t=2026-01-22T04:15:33+0000 lvl=warn msg=\"Error restarting forwarder\" name=http-8003-f36bc27d-9bfa-4906-a52f-f774a0bf99c6 err=\"failed to start tunnel: session closed\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m  Stopping...\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# Launch Streamlit via Ngrok\n",
        "# ===============================\n",
        "import threading, time\n",
        "def run_streamlit():\n",
        "    !streamlit run app.py --server.port 8501 --server.address 0.0.0.0\n",
        "threading.Thread(target=run_streamlit).start()\n",
        "time.sleep(5)\n",
        "streamlit_url = ngrok.connect(8501)\n",
        "print(\"Streamlit public URL:\", streamlit_url)"
      ],
      "metadata": {
        "id": "637cjqQhjVBN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebc7e47e-d54c-433f-b99b-af0f970df994"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  URL: \u001b[0m\u001b[1mhttp://0.0.0.0:8501\u001b[0m\n",
            "\u001b[0m\n",
            "Streamlit public URL: NgrokTunnel: \"https://renowned-zuri-coleopterous.ngrok-free.dev\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QH1ZdgZMrti6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}