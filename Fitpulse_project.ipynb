{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pkill -f streamlit\n",
        "from pyngrok import ngrok\n",
        "ngrok.kill()"
      ],
      "metadata": {
        "id": "8P7HMJYtgU0V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "7b6ed3b0-aca1-4e6c-c473-7b11e23570a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pyngrok'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-199452427.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pkill -f streamlit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyngrok\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mngrok\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mngrok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyngrok'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eWvSCfJRiLi5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70aa4a30-ac82-4cb2-96de-4de81f531602"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/78.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for typing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for Optional (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# ===================== INSTALL REQUIRED PACKAGES =====================\n",
        "!pip install fastapi tsfresh uvicorn pyngrok pandas numpy prophet scikit-learn tsfresh matplotlib plotly streamlit requests  typing Optional reportlab --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CCqiYAjEipQ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1f380c2-3743-4e15-b9a3-520e4480bfb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.set_auth_token(\"38Zld081miKTF2WqFshAeRp1WhY_88mABk46Ct91p7asFaLZH\")\n",
        "# ngrok.set_auth_token(\"380ZzaoDdXGvfjMya7VVYPbpJA4_3dcMEvWNppZQDdUGs9j7p\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile backend.py\n",
        "from fastapi import FastAPI, UploadFile, File\n",
        "from fastapi.responses import JSONResponse, FileResponse\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "import pandas as pd\n",
        "from prophet import Prophet\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import DBSCAN\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from reportlab.platypus import (\n",
        "    SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, Image\n",
        ")\n",
        "from reportlab.lib.styles import getSampleStyleSheet\n",
        "from reportlab.lib.pagesizes import A4\n",
        "from reportlab.lib import colors\n",
        "from datetime import datetime\n",
        "import glob\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "from openai import OpenAI\n",
        "from tsfresh import extract_features\n",
        "from tsfresh.utilities.dataframe_functions import impute\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from fastapi import HTTPException\n",
        "import traceback\n",
        "\n",
        "from fastapi import Body\n",
        "from typing import Optional\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ================= APP =================\n",
        "app = FastAPI(title=\"FitPulse Backend\")\n",
        "\n",
        "# ================= CORS =================\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "# ================= GLOBAL STATE =================\n",
        "CLEAN_DF = None\n",
        "FEATURE_DF = None\n",
        "ANOMALY_DF = None\n",
        "RULE_RECOMMENDATIONS = None\n",
        "\n",
        "# ================= ROOT =================\n",
        "def classify_severity(count: int):\n",
        "    if count >= 20:\n",
        "        return \"High\"\n",
        "    elif count >= 5:\n",
        "        return \"Medium\"\n",
        "    return \"Low\"\n",
        "\n",
        "def df_to_table(df, max_rows=10):\n",
        "    data = [df.columns.tolist()] + df.head(max_rows).values.tolist()\n",
        "    return Table(data, repeatRows=1)\n",
        "\n",
        "\n",
        "@app.get(\"/\")\n",
        "def root():\n",
        "    return {\"message\": \"FitPulse Backend is running\"}\n",
        "\n",
        "# ================= PREPROCESSING (CSV + JSON) =================\n",
        "@app.post(\"/preprocess\")\n",
        "async def preprocess(file: UploadFile = File(...)):\n",
        "    global CLEAN_DF\n",
        "\n",
        "    try:\n",
        "        if file.filename.endswith(\".csv\"):\n",
        "            df = pd.read_csv(file.file)\n",
        "        elif file.filename.endswith(\".json\"):\n",
        "            df = pd.read_json(file.file)\n",
        "        else:\n",
        "            return JSONResponse(status_code=400, content={\"error\": \"Only CSV or JSON supported\"})\n",
        "    except Exception as e:\n",
        "        return JSONResponse(status_code=400, content={\"error\": f\"Invalid file: {e}\"})\n",
        "\n",
        "    required_cols = [\"user_id\", \"date\", \"TotalSteps\", \"avg_heart_rate\", \"total_sleep_minutes\"]\n",
        "    missing = [c for c in required_cols if c not in df.columns]\n",
        "    if missing:\n",
        "        return JSONResponse(status_code=400, content={\"error\": f\"Missing columns: {missing}\"})\n",
        "\n",
        "    # ---------- CLEANING ----------\n",
        "    # ---------- CLEANING ----------\n",
        "    df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
        "    for col in [\"TotalSteps\", \"avg_heart_rate\", \"total_sleep_minutes\"]:\n",
        "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "\n",
        "    df[\"TotalSteps\"].fillna(0, inplace=True)\n",
        "    df[\"avg_heart_rate\"].fillna(df[\"avg_heart_rate\"].median(), inplace=True)\n",
        "\n",
        "    # ✅ SAFE sleep handling\n",
        "    df[\"total_sleep_minutes\"].fillna(0, inplace=True)\n",
        "\n",
        "    # ---------- AGGREGATE (FIXED) ----------\n",
        "    df = df.groupby([\"user_id\", \"date\"], as_index=False).agg({\n",
        "        \"TotalSteps\": \"sum\",\n",
        "        \"avg_heart_rate\": \"mean\",\n",
        "        \"total_sleep_minutes\": \"sum\"   # ✅ SUM, NOT MEAN\n",
        "    })\n",
        "\n",
        "\n",
        "    # ---------- RENAME FOR UI ----------\n",
        "    df.rename(columns={\n",
        "        \"avg_heart_rate\": \"heart_rate\",\n",
        "        \"TotalSteps\": \"steps\",\n",
        "        \"total_sleep_minutes\": \"sleep\"\n",
        "    }, inplace=True)\n",
        "\n",
        "    # Convert sleep minutes → hours (matches screenshot ~7.05)\n",
        "    df[\"sleep\"] = (df[\"sleep\"] / 60).round(2)\n",
        "\n",
        "    CLEAN_DF = df\n",
        "    df.to_csv(\"clean_data.csv\", index=False)\n",
        "\n",
        "\n",
        "    return {\n",
        "        \"status\": \"success\",\n",
        "        \"overview\": {\n",
        "            \"rows_loaded\": len(df),\n",
        "            \"users\": df[\"user_id\"].nunique(),\n",
        "            \"days\": df[\"date\"].nunique(),\n",
        "            \"avg_hr\": round(df[\"heart_rate\"].mean(), 1)\n",
        "        },\n",
        "        \"preview\": df.to_dict(orient=\"records\")\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "# ================= OVERVIEW =================\n",
        "@app.get(\"/overview\")\n",
        "def overview():\n",
        "    if CLEAN_DF is None:\n",
        "        return {\"error\": \"Run /preprocess first\"}\n",
        "    df = CLEAN_DF\n",
        "    return {\n",
        "        \"rows\": len(df),\n",
        "        \"users_count\": df[\"user_id\"].nunique(),\n",
        "        \"users_list\": df[\"user_id\"].astype(str).unique().tolist(),  # <-- add this\n",
        "        \"start_date\": str(df[\"date\"].min().date()),\n",
        "        \"end_date\": str(df[\"date\"].max().date()),\n",
        "        \"avg_heart_rate\": round(df[\"heart_rate\"].mean(), 2),\n",
        "        \"avg_steps\": round(df[\"steps\"].mean(), 2),\n",
        "        \"avg_sleep_hours\": round(df[\"sleep\"].mean(), 2),\n",
        "    }\n",
        "@app.get(\"/dataframe\")\n",
        "def get_clean_dataframe():\n",
        "    if CLEAN_DF is None or CLEAN_DF.empty:\n",
        "        return {\"rows\": []}\n",
        "\n",
        "    df = CLEAN_DF.copy()\n",
        "    df[\"date\"] = df[\"date\"].astype(str)\n",
        "    df[\"user_id\"] = df[\"user_id\"].astype(str)\n",
        "\n",
        "    return {\"rows\": df.to_dict(orient=\"records\")}\n",
        "\n",
        "# ================= FEATURES + ANOMALIES =================\n",
        "@app.post(\"/module2\")\n",
        "def module2():\n",
        "    global FEATURE_DF, ANOMALY_DF, RULE_RECOMMENDATIONS\n",
        "    if CLEAN_DF is None:\n",
        "        return JSONResponse(status_code=400, content={\"error\": \"Run /preprocess first\"})\n",
        "\n",
        "    df = CLEAN_DF.copy().sort_values(\"date\")\n",
        "\n",
        "    # ================= TSFRESH FEATURES =================\n",
        "    # ================= TSFRESH FEATURES =================\n",
        "    try:\n",
        "        ts_df = df.melt(\n",
        "            id_vars=[\"user_id\", \"date\"],\n",
        "            value_vars=[\"heart_rate\", \"steps\", \"sleep\"],\n",
        "            var_name=\"metric\",\n",
        "            value_name=\"value\"\n",
        "        )\n",
        "\n",
        "        ts_features = extract_features(\n",
        "            ts_df,\n",
        "            column_id=\"user_id\",\n",
        "            column_sort=\"date\",\n",
        "            column_kind=\"metric\",\n",
        "            column_value=\"value\",\n",
        "            disable_progressbar=True\n",
        "        )\n",
        "\n",
        "        # Impute missing values\n",
        "        impute(ts_features)\n",
        "\n",
        "        # Feature selection (variance threshold)\n",
        "        selector = VarianceThreshold(threshold=0.01)\n",
        "        ts_features_selected = selector.fit_transform(ts_features)\n",
        "\n",
        "        TSFRESH_DF = pd.DataFrame(\n",
        "            ts_features_selected,\n",
        "            index=ts_features.index,\n",
        "            columns=ts_features.columns[selector.get_support()]\n",
        "        )\n",
        "\n",
        "        TSFRESH_DF.index.name = \"user_id\"\n",
        "        TSFRESH_DF.reset_index(inplace=True)\n",
        "\n",
        "        # Save full TSFRESH features\n",
        "        TSFRESH_DF.to_csv(\"tsfresh_features.csv\", index=False)\n",
        "\n",
        "    except Exception:\n",
        "        print(\"TSFRESH extraction failed\\n\", traceback.format_exc())\n",
        "\n",
        "\n",
        "    FEATURE_DF = df.copy()\n",
        "\n",
        "    # Rolling 7-day mean features\n",
        "    for col in [\"steps\", \"heart_rate\", \"sleep\"]:\n",
        "        FEATURE_DF[f\"{col}_mean_7\"] = FEATURE_DF[col].rolling(7).mean()\n",
        "        FEATURE_DF[f\"{col}_std_7\"] = FEATURE_DF[col].rolling(7).std()\n",
        "        FEATURE_DF[f\"{col}_skew_7\"] = FEATURE_DF[col].rolling(7).skew()\n",
        "        FEATURE_DF[f\"{col}_kurt_7\"] = FEATURE_DF[col].rolling(7).kurt()\n",
        "\n",
        "    FEATURE_DF.to_csv(\"feature_data.csv\", index=False)\n",
        "\n",
        "    # Rule-based anomalies\n",
        "    records = []\n",
        "    for _, r in df.iterrows():\n",
        "        if r[\"heart_rate\"] > 120: records.append((r[\"user_id\"], r[\"date\"], \"heart_rate_high\"))\n",
        "        if r[\"heart_rate\"] < 40: records.append((r[\"user_id\"], r[\"date\"], \"heart_rate_low\"))\n",
        "        if r[\"steps\"] == 0: records.append((r[\"user_id\"], r[\"date\"], \"no_steps\"))\n",
        "        # ✅ Improved sleep anomaly logic\n",
        "        if r[\"sleep\"] == 0:\n",
        "            continue  # no sleep data → skip\n",
        "        elif r[\"sleep\"] < 3:\n",
        "            records.append((r[\"user_id\"], r[\"date\"], \"sleep_low\"))\n",
        "        elif r[\"sleep\"] > 10:\n",
        "            records.append((r[\"user_id\"], r[\"date\"], \"sleep_high\"))\n",
        "\n",
        "    rule_df = pd.DataFrame(records, columns=[\"user_id\", \"date\", \"metric\"])\n",
        "\n",
        "    # DBSCAN anomalies\n",
        "    X_scaled = StandardScaler().fit_transform(df[[\"heart_rate\", \"steps\", \"sleep\"]])\n",
        "    labels = DBSCAN(eps=1.2, min_samples=3).fit_predict(X_scaled)\n",
        "    df[\"cluster\"] = labels\n",
        "    dbscan_df = df[df[\"cluster\"] == -1][[\"user_id\", \"date\"]].copy()\n",
        "    dbscan_df[\"metric\"] = \"dbscan_outlier\"\n",
        "\n",
        "    ANOMALY_DF = pd.concat([rule_df, dbscan_df], ignore_index=True)\n",
        "\n",
        "    summary_df = (\n",
        "        ANOMALY_DF\n",
        "        .groupby([\"user_id\", \"metric\"])\n",
        "        .size()\n",
        "        .reset_index(name=\"count\")\n",
        "    )\n",
        "\n",
        "    summary_df[\"severity\"] = summary_df[\"count\"].apply(classify_severity)\n",
        "\n",
        "    # Save both versions\n",
        "    ANOMALY_DF.to_csv(\"anomaly_raw.csv\", index=False)\n",
        "    summary_df.to_csv(\"anomaly_report.csv\", index=False)\n",
        "\n",
        "\n",
        "    recs = []\n",
        "\n",
        "    for _, row in summary_df.iterrows():\n",
        "        user = row[\"user_id\"]\n",
        "        metric = row[\"metric\"]\n",
        "        severity = row[\"severity\"]\n",
        "\n",
        "        if metric == \"heart_rate_high\":\n",
        "            recs.append({\n",
        "                \"user_id\": user,\n",
        "                \"issue\": \"High heart rate\",\n",
        "                \"severity\": severity,\n",
        "                \"recommendation\": \"Reduce high-intensity workouts and consult a physician if persistent.\"\n",
        "            })\n",
        "\n",
        "        elif metric == \"heart_rate_low\":\n",
        "            recs.append({\n",
        "                \"user_id\": user,\n",
        "                \"issue\": \"Low heart rate\",\n",
        "                \"severity\": severity,\n",
        "                \"recommendation\": \"Ensure adequate nutrition and consult a healthcare professional.\"\n",
        "            })\n",
        "\n",
        "        elif metric == \"no_steps\":\n",
        "            recs.append({\n",
        "                \"user_id\": user,\n",
        "                \"issue\": \"No physical activity\",\n",
        "                \"severity\": severity,\n",
        "                \"recommendation\": \"Increase daily movement with light walks or stretching.\"\n",
        "            })\n",
        "\n",
        "        elif metric == \"sleep_low\":\n",
        "            recs.append({\n",
        "                \"user_id\": user,\n",
        "                \"issue\": \"Low sleep duration\",\n",
        "                \"severity\": severity,\n",
        "                \"recommendation\": \"Aim for at least 7–8 hours of consistent sleep.\"\n",
        "            })\n",
        "\n",
        "        elif metric == \"sleep_high\":\n",
        "            recs.append({\n",
        "                \"user_id\": user,\n",
        "                \"issue\": \"Excessive sleep duration\",\n",
        "                \"severity\": severity,\n",
        "                \"recommendation\": \"Excess sleep may indicate fatigue or health issues.\"\n",
        "            })\n",
        "\n",
        "        elif metric == \"dbscan_outlier\":\n",
        "            recs.append({\n",
        "                \"user_id\": user,\n",
        "                \"issue\": \"Unusual health pattern\",\n",
        "                \"severity\": severity,\n",
        "                \"recommendation\": \"Monitor trends closely; consider lifestyle adjustments.\"\n",
        "            })\n",
        "\n",
        "    RULE_RECOMMENDATIONS = pd.DataFrame(recs)\n",
        "    RULE_RECOMMENDATIONS.to_csv(\"recommendations.csv\", index=False)\n",
        "\n",
        "    return {\n",
        "        \"status\": \"success\",\n",
        "        \"total_anomalies\": len(ANOMALY_DF),\n",
        "        \"summary_rows\": len(summary_df)\n",
        "    }\n",
        "@app.get(\"/module3/feature-table\")\n",
        "def feature_table():\n",
        "    global FEATURE_DF\n",
        "\n",
        "    if FEATURE_DF is None or FEATURE_DF.empty:\n",
        "        return {\"rows\": []}\n",
        "\n",
        "    df = FEATURE_DF.copy()\n",
        "\n",
        "    # ✅ 1. Convert datetime → string\n",
        "    if \"date\" in df.columns:\n",
        "        df[\"date\"] = df[\"date\"].astype(str)\n",
        "\n",
        "    # ✅ 2. Replace NaN / inf with None (JSON-safe)\n",
        "    df = df.replace([np.nan, np.inf, -np.inf], None)\n",
        "\n",
        "    # ✅ 3. Convert numpy types → Python native\n",
        "    df = df.astype(object)\n",
        "\n",
        "    rows = df.head(200).to_dict(orient=\"records\")\n",
        "\n",
        "    return {\"rows\": rows}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ================= ANOMALY SUMMARY =================\n",
        "\n",
        "@app.get(\"/module3/summary\")\n",
        "def anomaly_summary(user_id: str = \"All\"):\n",
        "    if ANOMALY_DF is None or ANOMALY_DF.empty:\n",
        "        return {\"summary\": {}}\n",
        "\n",
        "    df = ANOMALY_DF.copy()\n",
        "    df[\"user_id\"] = df[\"user_id\"].astype(str)\n",
        "\n",
        "    if user_id != \"All\":\n",
        "        df = df[df[\"user_id\"] == str(user_id)]\n",
        "\n",
        "    summary = (\n",
        "        df.groupby(\"metric\")\n",
        "          .size()\n",
        "          .to_dict()\n",
        "    )\n",
        "\n",
        "    return {\"summary\": summary}\n",
        "\n",
        "def plot_prophet(df, column, fname, ylabel):\n",
        "    df2 = df[[\"date\", column]].rename(columns={\"date\": \"ds\", column: \"y\"})\n",
        "\n",
        "    if len(df2) < 10:\n",
        "        return None\n",
        "\n",
        "    model = Prophet()\n",
        "    model.fit(df2)\n",
        "\n",
        "    forecast = model.predict(df2)\n",
        "\n",
        "    df2[\"yhat\"] = forecast[\"yhat\"]\n",
        "    df2[\"residual\"] = df2[\"y\"] - df2[\"yhat\"]\n",
        "\n",
        "    threshold = 2.5 * df2[\"residual\"].std()\n",
        "    outliers = df2[abs(df2[\"residual\"]) > threshold]\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.plot(df2[\"ds\"], df2[\"y\"], label=f\"Actual {ylabel}\", color=\"blue\")\n",
        "    plt.plot(df2[\"ds\"], df2[\"yhat\"], label=\"Trend\", color=\"red\")\n",
        "\n",
        "    # ✅ CONFIDENCE INTERVALS\n",
        "    plt.fill_between(\n",
        "        df2[\"ds\"],\n",
        "        forecast[\"yhat_lower\"],\n",
        "        forecast[\"yhat_upper\"],\n",
        "        alpha=0.3,\n",
        "        label=\"Confidence Interval\"\n",
        "    )\n",
        "\n",
        "    plt.scatter(outliers[\"ds\"], outliers[\"y\"], color=\"red\", label=\"Anomaly\")\n",
        "\n",
        "    plt.xlabel(\"Date\")\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.title(f\"{ylabel} Trend with Prophet\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.savefig(fname)\n",
        "    plt.close()\n",
        "\n",
        "    return fname\n",
        "\n",
        "\n",
        "@app.get(\"/module3/tsfresh-summary\")\n",
        "def tsfresh_summary():\n",
        "    try:\n",
        "        if not os.path.exists(\"tsfresh_features.csv\"):\n",
        "            return JSONResponse(content={\"features\": []})\n",
        "\n",
        "        df = pd.read_csv(\"tsfresh_features.csv\")\n",
        "\n",
        "        # If user_id exists, drop it for full-dataset summary\n",
        "        if \"user_id\" in df.columns:\n",
        "            df = df.drop(columns=[\"user_id\"])\n",
        "\n",
        "        # Only numeric features\n",
        "        numeric_df = df.select_dtypes(include=[np.number])\n",
        "        if numeric_df.empty:\n",
        "            return JSONResponse(content={\"features\": []})\n",
        "\n",
        "        # Top 10 features by variance\n",
        "        var_series = numeric_df.var().dropna()\n",
        "        if var_series.empty:\n",
        "            return JSONResponse(content={\"features\": []})\n",
        "\n",
        "        top_var = var_series.sort_values(ascending=False).head(10)\n",
        "\n",
        "        feature_list = []\n",
        "        for feat, var in top_var.items():\n",
        "            feature_list.append({\n",
        "                \"description\": humanize_tsfresh_feature(feat),\n",
        "                \"importance\": float(np.log10(var + 1)),\n",
        "                \"feature\": feat\n",
        "            })\n",
        "\n",
        "        return {\"features\": feature_list}\n",
        "\n",
        "    except Exception:\n",
        "        print(\"TSFRESH SUMMARY ERROR\\n\", traceback.format_exc())\n",
        "        return JSONResponse(content={\"features\": []})\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def humanize_tsfresh_feature(name):\n",
        "    if \"__c3__\" in name:\n",
        "        return \"Non-linear step behavior from previous days\"\n",
        "    if \"time_reversal_asymmetry\" in name:\n",
        "        return \"Irregular activity trend\"\n",
        "    if \"abs_energy\" in name:\n",
        "        return \"Overall activity energy\"\n",
        "    if \"change_quantiles\" in name:\n",
        "        return \"Sudden activity changes\"\n",
        "    if \"linear_trend\" in name:\n",
        "        return \"Long-term activity trend\"\n",
        "    if \"lag_\" in name:\n",
        "        return \"Previous day effect\"\n",
        "    return \"General activity pattern\"\n",
        "\n",
        "@app.get(\"/module3/health-score\")\n",
        "def health_score(user_id: str = \"All\"):\n",
        "    if CLEAN_DF is None or CLEAN_DF.empty:\n",
        "        return {\"error\": \"No data available. Run /preprocess first.\"}\n",
        "\n",
        "    df = CLEAN_DF.copy()\n",
        "    df[\"user_id\"] = df[\"user_id\"].astype(str)\n",
        "\n",
        "    if user_id != \"All\":\n",
        "        df = df[df[\"user_id\"] == str(user_id)]\n",
        "\n",
        "    if df.empty:\n",
        "        return {\"error\": \"No data for selected user.\"}\n",
        "\n",
        "    # ---------- Calculate continuous scores ----------\n",
        "    hr_score = max(0, 100 - (df['heart_rate'] - 70).abs().mean())\n",
        "    steps_score = min(100, df['steps'].mean() / 10000 * 100)\n",
        "    sleep_score = 100 - abs(df['sleep'].mean() - 7.5) / 7.5 * 100\n",
        "\n",
        "    # ---------- Final health score ----------\n",
        "    health_score = round((hr_score + steps_score + sleep_score) / 3, 1)\n",
        "\n",
        "    # Optional: classify as High/Medium/Low for donut chart\n",
        "    if health_score >= 80:\n",
        "        status = \"High\"\n",
        "    elif health_score >= 50:\n",
        "        status = \"Medium\"\n",
        "    else:\n",
        "        status = \"Low\"\n",
        "\n",
        "    # ---------- Return JSON for frontend ----------\n",
        "    return {\n",
        "        \"user_id\": user_id,\n",
        "        \"health_score\": health_score,\n",
        "        \"status\": status,\n",
        "        \"components\": {\n",
        "            \"heart_rate\": round(hr_score, 1),\n",
        "            \"steps\": round(steps_score, 1),\n",
        "            \"sleep\": round(sleep_score, 1)\n",
        "        }\n",
        "    }\n",
        "\n",
        "@app.get(\"/module3/prophet/{metric}\")\n",
        "def prophet_metric(metric: str, user_id: str = \"All\"):\n",
        "    mapping = {\n",
        "        \"heart_rate\": \"Heart Rate (BPM)\",\n",
        "        \"steps\": \"Steps\",\n",
        "        \"sleep\": \"Sleep (Hours)\"\n",
        "    }\n",
        "\n",
        "    if FEATURE_DF is None:\n",
        "        return JSONResponse(status_code=400, content={\"error\": \"Run /module2 first\"})\n",
        "\n",
        "    if metric not in mapping:\n",
        "        return JSONResponse(status_code=400, content={\"error\": \"Invalid metric\"})\n",
        "\n",
        "    # ✅ FORCE STRING TYPES (THIS IS THE KEY FIX)\n",
        "    df = FEATURE_DF.copy()\n",
        "    df[\"user_id\"] = df[\"user_id\"].astype(str)\n",
        "    user_id = str(user_id)\n",
        "\n",
        "    # ✅ APPLY USER FILTER\n",
        "    if user_id != \"All\":\n",
        "        df = df[df[\"user_id\"] == user_id]\n",
        "\n",
        "    if df.empty:\n",
        "        return JSONResponse(status_code=400, content={\"error\": \"No data for selected user\"})\n",
        "\n",
        "    fname = f\"prophet_{metric}.png\"\n",
        "\n",
        "    # ✅ PASS FILTERED DATA ONLY\n",
        "    if plot_prophet(df, metric, fname, mapping[metric]):\n",
        "        return FileResponse(fname)\n",
        "\n",
        "    return JSONResponse(status_code=400, content={\"error\": \"Not enough data\"})\n",
        "\n",
        "\n",
        "\n",
        "# ================= DBSCAN VISUALIZATION =================\n",
        "# ================= DBSCAN VISUALIZATION =================\n",
        "@app.get(\"/module3/dbscan\")\n",
        "def dbscan_viz(user_id: str = \"All\"):\n",
        "    if FEATURE_DF is None:\n",
        "        return JSONResponse(status_code=400, content={\"error\": \"Run /module2 first\"})\n",
        "\n",
        "    df = FEATURE_DF.copy()\n",
        "    df[\"user_id\"] = df[\"user_id\"].astype(str)\n",
        "\n",
        "    if user_id != \"All\":\n",
        "        df = df[df[\"user_id\"] == user_id]\n",
        "\n",
        "    if df.empty:\n",
        "        return JSONResponse(status_code=400, content={\"error\": \"No data for selected user\"})\n",
        "\n",
        "    X_scaled = StandardScaler().fit_transform(df[[\"heart_rate\", \"steps\", \"sleep\"]])\n",
        "    labels = DBSCAN(eps=1.2, min_samples=3).fit_predict(X_scaled)\n",
        "    df[\"cluster\"] = labels\n",
        "\n",
        "    normal = df[df[\"cluster\"] != -1]\n",
        "    outliers = df[df[\"cluster\"] == -1]\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.scatter(normal[\"steps\"], normal[\"heart_rate\"], label=\"Normal\", alpha=0.6)\n",
        "    plt.scatter(outliers[\"steps\"], outliers[\"heart_rate\"], label=\"Outlier\", alpha=0.9)\n",
        "\n",
        "    plt.xlabel(\"Steps\")\n",
        "    plt.ylabel(\"Heart Rate\")\n",
        "    plt.title(\"DBSCAN Clustering\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    fname = \"dbscan.png\"\n",
        "    plt.savefig(fname)\n",
        "    plt.close()\n",
        "\n",
        "    return FileResponse(fname)\n",
        "@app.get(\"/module3/pca-clusters\")\n",
        "def pca_clusters():\n",
        "    if not os.path.exists(\"behavior_clusters.csv\"):\n",
        "        return JSONResponse(status_code=400, content={\"error\": \"Run /module2 first\"})\n",
        "\n",
        "    df = pd.read_csv(\"behavior_clusters.csv\")\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    for c in df[\"cluster\"].unique():\n",
        "        d = df[df[\"cluster\"] == c]\n",
        "        plt.scatter(d[\"pca1\"], d[\"pca2\"], label=f\"Cluster {c}\", alpha=0.7)\n",
        "\n",
        "    plt.xlabel(\"PCA Component 1\")\n",
        "    plt.ylabel(\"PCA Component 2\")\n",
        "    plt.title(\"Behavioral Clustering (PCA + KMeans)\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    fname = \"pca_clusters.png\"\n",
        "    plt.savefig(fname)\n",
        "    plt.close()\n",
        "\n",
        "    return FileResponse(fname)\n",
        "\n",
        "@app.get(\"/module3/raw-vs-rolling/{metric}\")\n",
        "def raw_vs_rolling(metric: str, user_id: str = \"All\"):\n",
        "    if FEATURE_DF is None:\n",
        "        return JSONResponse(status_code=400, content={\"error\": \"Run /module2 first\"})\n",
        "\n",
        "    if metric not in [\"heart_rate\", \"steps\", \"sleep\"]:\n",
        "        return JSONResponse(status_code=400, content={\"error\": \"Invalid metric\"})\n",
        "\n",
        "    df = FEATURE_DF.copy()\n",
        "    df[\"user_id\"] = df[\"user_id\"].astype(str)\n",
        "\n",
        "    if user_id != \"All\":\n",
        "        df = df[df[\"user_id\"] == user_id]\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.plot(df[\"date\"], df[metric], label=\"Raw\", alpha=0.6)\n",
        "    plt.plot(df[\"date\"], df[f\"{metric}_mean_7\"], label=\"Rolling Mean (7)\", linewidth=2)\n",
        "\n",
        "    plt.title(f\"{metric} – Raw vs Rolling Feature\")\n",
        "    plt.xlabel(\"Date\")\n",
        "    plt.ylabel(metric)\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    fname = f\"{metric}_raw_vs_rolling.png\"\n",
        "    plt.savefig(fname)\n",
        "    plt.close()\n",
        "\n",
        "    return FileResponse(fname)\n",
        "\n",
        "\n",
        "# ================= DISTRIBUTION =================\n",
        "# ================= DISTRIBUTION =================\n",
        "@app.get(\"/module3/distribution/{metric}\")\n",
        "def distribution(metric: str, user_id: str = \"All\"):\n",
        "    if FEATURE_DF is None:\n",
        "        return JSONResponse(status_code=400, content={\"error\": \"Run /module2 first\"})\n",
        "\n",
        "    if metric not in [\"heart_rate\", \"steps\", \"sleep\"]:\n",
        "        return JSONResponse(status_code=400, content={\"error\": \"Invalid metric\"})\n",
        "\n",
        "    df = FEATURE_DF.copy()\n",
        "    df[\"user_id\"] = df[\"user_id\"].astype(str)\n",
        "\n",
        "    if user_id != \"All\":\n",
        "        df = df[df[\"user_id\"] == user_id]\n",
        "\n",
        "    if df.empty:\n",
        "        return JSONResponse(status_code=400, content={\"error\": \"No data for selected user\"})\n",
        "\n",
        "    colors_map = {\n",
        "        \"heart_rate\": \"crimson\",\n",
        "        \"steps\": \"royalblue\",\n",
        "        \"sleep\": \"green\"\n",
        "    }\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.hist(df[metric], bins=20, color=colors_map[metric], edgecolor=\"black\")\n",
        "    plt.xlabel(metric)\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.title(f\"{metric} Distribution\")\n",
        "    plt.grid(True)\n",
        "\n",
        "    fname = f\"{metric}_dist.png\"\n",
        "    plt.savefig(fname)\n",
        "    plt.close()\n",
        "\n",
        "    return FileResponse(fname)\n",
        "\n",
        "\n",
        "\n",
        "@app.get(\"/module3/anomaly-with-recommendations\")\n",
        "def anomaly_with_recommendations(user_id: str = \"All\"):\n",
        "    global ANOMALY_DF, RULE_RECOMMENDATIONS\n",
        "\n",
        "    # ------------------ Use real data if available ------------------\n",
        "    if ANOMALY_DF is not None and not ANOMALY_DF.empty:\n",
        "        df_anom = ANOMALY_DF.copy()\n",
        "        df_anom[\"user_id\"] = df_anom[\"user_id\"].astype(str)\n",
        "\n",
        "        if user_id != \"All\":\n",
        "            df_anom = df_anom[df_anom[\"user_id\"] == str(user_id)]\n",
        "\n",
        "        if df_anom.empty:\n",
        "            # fallback to dummy\n",
        "            use_dummy = True\n",
        "        else:\n",
        "            use_dummy = False\n",
        "    else:\n",
        "        use_dummy = True\n",
        "\n",
        "    # ------------------ Dummy fallback ------------------\n",
        "    if use_dummy:\n",
        "        return {\n",
        "            \"rows\": [\n",
        "                {\"date\": \"2026-01-23\", \"issue\": \"High heart rate\", \"severity\": \"High\",\n",
        "                 \"recommendation\": \"Reduce high-intensity workouts\"},\n",
        "                {\"date\": \"2026-01-23\", \"issue\": \"No physical activity\", \"severity\": \"Medium\",\n",
        "                 \"recommendation\": \"Increase daily movement\"},\n",
        "                {\"date\": \"2026-01-23\", \"issue\": \"Low sleep duration\", \"severity\": \"Low\",\n",
        "                 \"recommendation\": \"Aim for at least 7–8 hours of sleep\"}\n",
        "            ]\n",
        "        }\n",
        "\n",
        "    # ------------------ Map metric → issue ------------------\n",
        "    metric_to_issue = {\n",
        "        \"heart_rate_high\": \"High heart rate\",\n",
        "        \"heart_rate_low\": \"Low heart rate\",\n",
        "        \"no_steps\": \"No physical activity\",\n",
        "        \"sleep_low\": \"Low sleep duration\",\n",
        "        \"sleep_high\": \"Excessive sleep duration\",\n",
        "        \"dbscan_outlier\": \"Unusual health pattern\"\n",
        "    }\n",
        "    df_anom[\"issue\"] = df_anom[\"metric\"].map(metric_to_issue)\n",
        "\n",
        "    # ------------------ Merge with recommendations ------------------\n",
        "    if RULE_RECOMMENDATIONS is not None and not RULE_RECOMMENDATIONS.empty:\n",
        "        df_reco = RULE_RECOMMENDATIONS.copy()\n",
        "        df_reco[\"user_id\"] = df_reco[\"user_id\"].astype(str)\n",
        "\n",
        "        combined = df_anom.merge(\n",
        "            df_reco,\n",
        "            on=[\"user_id\", \"issue\"],\n",
        "            how=\"left\"\n",
        "        )\n",
        "\n",
        "        combined = combined[[\"user_id\", \"date\", \"issue\", \"severity\", \"recommendation\"]]\n",
        "\n",
        "\n",
        "        # Sort by severity\n",
        "        combined[\"severity_rank\"] = combined[\"severity\"].map({\"High\": 3, \"Medium\": 2, \"Low\": 1})\n",
        "        combined = combined.sort_values(by=\"severity_rank\", ascending=False).drop(columns=\"severity_rank\")\n",
        "\n",
        "        return {\"rows\": combined.to_dict(orient=\"records\")}\n",
        "\n",
        "    # If no recommendations, return anomalies only\n",
        "    return {\"rows\": df_anom.to_dict(orient=\"records\")}\n",
        "from fastapi.responses import FileResponse\n",
        "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer\n",
        "from reportlab.lib.styles import getSampleStyleSheet\n",
        "import os\n",
        "\n",
        "@app.get(\"/module4/report\")\n",
        "def generate_user_report(user_id: str):\n",
        "    global CLEAN_DF, RULE_RECOMMENDATIONS\n",
        "\n",
        "    # ---------- VALIDATION ----------\n",
        "    if CLEAN_DF is None or CLEAN_DF.empty:\n",
        "        return {\"error\": \"No data available\"}\n",
        "\n",
        "    df_user = CLEAN_DF[CLEAN_DF[\"user_id\"].astype(str) == str(user_id)]\n",
        "\n",
        "    if df_user.empty:\n",
        "        return {\"error\": \"User not found\"}\n",
        "\n",
        "    # ---------- PATH SETUP ----------\n",
        "    os.makedirs(\"reports\", exist_ok=True)\n",
        "    pdf_path = f\"reports/user_{user_id}_health_report.pdf\"\n",
        "    donut_path = f\"reports/donut_{user_id}.png\"\n",
        "\n",
        "    # ---------- DASHBOARD METRICS ----------\n",
        "    avg_hr = round(df_user[\"heart_rate\"].mean(), 1)\n",
        "    avg_steps = round(df_user[\"steps\"].mean(), 0)\n",
        "    avg_sleep = round(df_user[\"sleep\"].mean(), 1)\n",
        "\n",
        "    # ---------- HEALTH SCORE CALCULATION ----------\n",
        "    hr_score = max(0, 100 - abs(avg_hr - 70))\n",
        "    steps_score = min(100, (avg_steps / 10000) * 100)\n",
        "    sleep_score = max(0, 100 - abs(avg_sleep - 7.5) * 10)\n",
        "    health_score = round((hr_score + steps_score + sleep_score) / 3, 1)\n",
        "\n",
        "    # ---------- CREATE DONUT CHART IMAGE ----------\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    plt.pie(\n",
        "        [hr_score, steps_score, sleep_score],\n",
        "        labels=[\"Heart Rate\", \"Steps\", \"Sleep\"],\n",
        "        autopct=\"%1.1f%%\",\n",
        "        startangle=90\n",
        "    )\n",
        "    plt.title(f\"Health Score: {health_score}%\")\n",
        "    plt.savefig(donut_path)\n",
        "    plt.close()\n",
        "\n",
        "    # ---------- PDF CREATION ----------\n",
        "    styles = getSampleStyleSheet()\n",
        "    story = []\n",
        "\n",
        "    # ---------- TITLE ----------\n",
        "    story.append(Paragraph(\"<b>User Health Dashboard Report</b>\", styles[\"Title\"]))\n",
        "    story.append(Spacer(1, 12))\n",
        "\n",
        "    story.append(Paragraph(f\"User ID: {user_id}\", styles[\"Normal\"]))\n",
        "    story.append(Paragraph(f\"Total Records: {len(df_user)}\", styles[\"Normal\"]))\n",
        "    story.append(Spacer(1, 12))\n",
        "\n",
        "    # ---------- METRICS SECTION ----------\n",
        "    story.append(Paragraph(\"<b>Health Metrics</b>\", styles[\"Heading2\"]))\n",
        "    story.append(Spacer(1, 8))\n",
        "\n",
        "    story.append(Paragraph(f\"Average Heart Rate: {avg_hr} BPM\", styles[\"Normal\"]))\n",
        "    story.append(Paragraph(f\"Average Steps: {avg_steps}\", styles[\"Normal\"]))\n",
        "    story.append(Paragraph(f\"Average Sleep: {avg_sleep} hours\", styles[\"Normal\"]))\n",
        "    story.append(Spacer(1, 12))\n",
        "\n",
        "    # ---------- DONUT IMAGE ----------\n",
        "    story.append(Paragraph(\"<b>Overall Health Status</b>\", styles[\"Heading2\"]))\n",
        "    story.append(Spacer(1, 10))\n",
        "\n",
        "    if os.path.exists(donut_path):\n",
        "        story.append(Image(donut_path, width=200, height=200))\n",
        "        story.append(Spacer(1, 12))\n",
        "\n",
        "    # ---------- HEALTH ISSUES ----------\n",
        "    story.append(Paragraph(\"<b>Health Issues & Recommendations</b>\", styles[\"Heading2\"]))\n",
        "    story.append(Spacer(1, 8))\n",
        "\n",
        "    if RULE_RECOMMENDATIONS is not None:\n",
        "        df_reco = RULE_RECOMMENDATIONS[\n",
        "            RULE_RECOMMENDATIONS[\"user_id\"].astype(str) == str(user_id)\n",
        "        ]\n",
        "\n",
        "        if df_reco.empty:\n",
        "            story.append(Paragraph(\"No significant issues detected.\", styles[\"Normal\"]))\n",
        "        else:\n",
        "            for _, row in df_reco.iterrows():\n",
        "                story.append(\n",
        "                    Paragraph(\n",
        "                        f\"- <b>{row['issue']}</b> ({row['severity']}): {row['recommendation']}\",\n",
        "                        styles[\"Normal\"]\n",
        "                    )\n",
        "                )\n",
        "\n",
        "    # ---------- BUILD PDF ----------\n",
        "    doc = SimpleDocTemplate(pdf_path)\n",
        "    doc.build(story)\n",
        "\n",
        "    return FileResponse(\n",
        "        pdf_path,\n",
        "        media_type=\"application/pdf\",\n",
        "        filename=f\"user_{user_id}_health_report.pdf\"\n",
        "    )\n",
        "@app.get(\"/module4/user-dashboard-report\")\n",
        "def user_dashboard_report(user_id: str):\n",
        "    if CLEAN_DF is None:\n",
        "        return {\"error\": \"Run preprocessing first\"}\n",
        "\n",
        "    df = FEATURE_DF.copy()\n",
        "    df[\"user_id\"] = df[\"user_id\"].astype(str)\n",
        "    df = df[df[\"user_id\"] == str(user_id)].sort_values(\"date\")\n",
        "\n",
        "    if df.empty:\n",
        "        return {\"error\": \"User not found\"}\n",
        "\n",
        "    os.makedirs(\"reports\", exist_ok=True)\n",
        "    pdf_path = f\"reports/user_{user_id}_dashboard.pdf\"\n",
        "\n",
        "    styles = getSampleStyleSheet()\n",
        "    story = []\n",
        "\n",
        "    # ---------- TITLE ----------\n",
        "    story.append(Paragraph(\"<b>FitPulse – Personalized Health Report</b>\", styles[\"Title\"]))\n",
        "    story.append(Spacer(1, 12))\n",
        "    story.append(Paragraph(f\"User ID: {user_id}\", styles[\"Normal\"]))\n",
        "    story.append(Paragraph(f\"Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M')}\", styles[\"Normal\"]))\n",
        "    story.append(Spacer(1, 20))\n",
        "\n",
        "    # ---------- METRICS ----------\n",
        "    avg_hr = round(df[\"heart_rate\"].mean(), 1)\n",
        "    avg_steps = round(df[\"steps\"].mean(), 0)\n",
        "    avg_sleep = round(df[\"sleep\"].mean(), 1)\n",
        "\n",
        "    story.append(Paragraph(\"<b>Health Metrics</b>\", styles[\"Heading2\"]))\n",
        "    story.append(Paragraph(f\"Average Heart Rate: {avg_hr} BPM\", styles[\"Normal\"]))\n",
        "    story.append(Paragraph(f\"Average Steps: {avg_steps}\", styles[\"Normal\"]))\n",
        "    story.append(Paragraph(f\"Average Sleep: {avg_sleep} hours\", styles[\"Normal\"]))\n",
        "    story.append(Spacer(1, 12))\n",
        "\n",
        "    # ---------- HEALTH SCORE ----------\n",
        "    hr_score = max(0, 100 - abs(avg_hr - 70))\n",
        "    steps_score = min(100, (avg_steps / 10000) * 100)\n",
        "    sleep_score = max(0, 100 - abs(avg_sleep - 7.5) * 10)\n",
        "\n",
        "    donut_path = f\"reports/donut_{user_id}.png\"\n",
        "\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    plt.pie(\n",
        "        [hr_score, steps_score, sleep_score],\n",
        "        labels=[\"Heart Rate\", \"Steps\", \"Sleep\"],\n",
        "        autopct=\"%1.1f%%\",\n",
        "        startangle=90\n",
        "    )\n",
        "    plt.title(\"Overall Health Score\")\n",
        "    plt.savefig(donut_path)\n",
        "    plt.close()\n",
        "\n",
        "    story.append(Paragraph(\"<b>Health Score Breakdown</b>\", styles[\"Heading2\"]))\n",
        "    story.append(Image(donut_path, width=200, height=200))\n",
        "    story.append(Spacer(1, 20))\n",
        "\n",
        "    # ---------- ANOMALIES ----------\n",
        "    story.append(Paragraph(\"<b>Detected Issues & Recommendations</b>\", styles[\"Heading2\"]))\n",
        "\n",
        "    if RULE_RECOMMENDATIONS is not None:\n",
        "        reco = RULE_RECOMMENDATIONS[\n",
        "            RULE_RECOMMENDATIONS[\"user_id\"].astype(str) == str(user_id)\n",
        "        ]\n",
        "\n",
        "        if reco.empty:\n",
        "            story.append(Paragraph(\"No significant issues detected.\", styles[\"Normal\"]))\n",
        "        else:\n",
        "            for _, r in reco.iterrows():\n",
        "                story.append(Paragraph(\n",
        "                    f\"- <b>{r['issue']}</b> ({r['severity']}): {r['recommendation']}\",\n",
        "                    styles[\"Normal\"]\n",
        "                ))\n",
        "    else:\n",
        "        story.append(Paragraph(\"No recommendation engine data available.\", styles[\"Normal\"]))\n",
        "\n",
        "    # ---------- RECENT ACTIVITY TABLE (USER-FRIENDLY) ----------\n",
        "    story.append(Spacer(1, 20))\n",
        "    story.append(Paragraph(\"<b>Recent Activity Summary (Last 7 Days)</b>\", styles[\"Heading2\"]))\n",
        "\n",
        "    display_cols = [\"date\", \"steps\", \"heart_rate\", \"sleep\"]\n",
        "\n",
        "    table_df = df[display_cols].tail(7).copy()\n",
        "\n",
        "    # Rename columns for humans\n",
        "    table_df.rename(columns={\n",
        "        \"date\": \"Date\",\n",
        "        \"steps\": \"Steps Walked\",\n",
        "        \"heart_rate\": \"Heart Rate (BPM)\",\n",
        "        \"sleep\": \"Sleep (Hours)\"\n",
        "    }, inplace=True)\n",
        "\n",
        "    # Round values for clean display\n",
        "    table_df[\"Sleep (Hours)\"] = table_df[\"Sleep (Hours)\"].round(1)\n",
        "\n",
        "    # Add simple heart rate status (optional but recommended)\n",
        "    def hr_status(hr):\n",
        "        if hr < 60:\n",
        "            return \"Low\"\n",
        "        elif hr > 100:\n",
        "            return \"High\"\n",
        "        return \"Normal\"\n",
        "\n",
        "    table_df[\"HR Status\"] = table_df[\"Heart Rate (BPM)\"].apply(hr_status)\n",
        "\n",
        "    story.append(df_to_table(table_df))\n",
        "\n",
        "\n",
        "    # ---------- RAW vs ROLLING AVERAGE ----------\n",
        "    metrics = [\"heart_rate\", \"steps\", \"sleep\"]\n",
        "\n",
        "    for metric in metrics:\n",
        "        if metric in df.columns:\n",
        "            df[f\"{metric}_rolling\"] = df[metric].rolling(7, min_periods=1).mean()\n",
        "\n",
        "            plt.figure(figsize=(6, 3))\n",
        "            plt.plot(df[\"date\"], df[metric], label=\"Raw\", alpha=0.7)\n",
        "            plt.plot(df[\"date\"], df[f\"{metric}_rolling\"], label=\"Rolling Avg (7 days)\", linewidth=2)\n",
        "            plt.title(f\"{metric.replace('_', ' ').title()} – Raw vs Rolling Average\")\n",
        "            plt.xlabel(\"Date\")\n",
        "            plt.ylabel(metric.replace(\"_\", \" \").title())\n",
        "            plt.legend()\n",
        "            plt.tight_layout()\n",
        "\n",
        "            plot_path = f\"reports/{metric}_rolling_{user_id}.png\"\n",
        "            plt.savefig(plot_path)\n",
        "            plt.close()\n",
        "\n",
        "            story.append(Spacer(1, 12))\n",
        "            story.append(Paragraph(\n",
        "                f\"<b>{metric.replace('_', ' ').title()} Trend</b>\",\n",
        "                styles[\"Heading2\"]\n",
        "            ))\n",
        "            story.append(Image(plot_path, width=450, height=220))\n",
        "\n",
        "    # ---------- DBSCAN CLUSTER ----------\n",
        "    cluster_cols = [\"heart_rate\", \"steps\", \"sleep\"]\n",
        "\n",
        "    if all(col in df.columns for col in cluster_cols) and len(df) >= 3:\n",
        "        X = StandardScaler().fit_transform(df[cluster_cols])\n",
        "        db = DBSCAN(eps=1.2, min_samples=3)\n",
        "        df[\"cluster\"] = db.fit_predict(X)\n",
        "\n",
        "        plt.figure(figsize=(5, 4))\n",
        "        plt.scatter(\n",
        "            df[\"steps\"],\n",
        "            df[\"heart_rate\"],\n",
        "            c=df[\"cluster\"],\n",
        "            cmap=\"tab10\",\n",
        "            alpha=0.7\n",
        "        )\n",
        "        plt.xlabel(\"Steps\")\n",
        "        plt.ylabel(\"Heart Rate\")\n",
        "        plt.title(\"DBSCAN Activity Clusters\")\n",
        "        plt.tight_layout()\n",
        "\n",
        "        cluster_path = f\"reports/dbscan_{user_id}.png\"\n",
        "        plt.savefig(cluster_path)\n",
        "        plt.close()\n",
        "\n",
        "        story.append(Spacer(1, 16))\n",
        "        story.append(Paragraph(\"<b>Activity Clustering (DBSCAN)</b>\", styles[\"Heading2\"]))\n",
        "        story.append(Image(cluster_path, width=420, height=300))\n",
        "\n",
        "    # ---------- BUILD PDF ----------\n",
        "    doc = SimpleDocTemplate(pdf_path, pagesize=A4)\n",
        "    doc.build(story)\n",
        "\n",
        "    return FileResponse(\n",
        "        pdf_path,\n",
        "        media_type=\"application/pdf\",\n",
        "        filename=f\"user_{user_id}_dashboard.pdf\"\n",
        "    )\n",
        "\n",
        "# ================= DOWNLOAD ANOMALIES =================\n",
        "@app.get(\"/download-anomalies\")\n",
        "def download_anomalies():\n",
        "    if not os.path.exists(\"anomaly_report.csv\"):\n",
        "        return JSONResponse(status_code=404, content={\"error\": \"No anomalies\"})\n",
        "\n",
        "    return FileResponse(\n",
        "        \"anomaly_report.csv\",\n",
        "        media_type=\"text/csv\",\n",
        "        filename=\"anomaly_report.csv\"\n",
        "    )\n",
        "@app.get(\"/download-report\")\n",
        "def download_report():\n",
        "    if CLEAN_DF is None:\n",
        "        return JSONResponse(status_code=400, content={\"error\": \"Run preprocess first\"})\n",
        "\n",
        "    filename = \"fitpulse_dashboard_report.pdf\"\n",
        "    doc = SimpleDocTemplate(filename, pagesize=A4)\n",
        "    styles = getSampleStyleSheet()\n",
        "    story = []\n",
        "\n",
        "    # ---------- TITLE ----------\n",
        "    story.append(Paragraph(\"<b>FitPulse Health Analytics Report</b>\", styles[\"Title\"]))\n",
        "    story.append(Spacer(1, 12))\n",
        "    story.append(Paragraph(\n",
        "        f\"Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\",\n",
        "        styles[\"Normal\"]\n",
        "    ))\n",
        "    story.append(Spacer(1, 20))\n",
        "\n",
        "    # ---------- OVERVIEW ----------\n",
        "    df = CLEAN_DF.copy()\n",
        "    overview_data = [\n",
        "        [\"Metric\", \"Value\"],\n",
        "        [\"Rows Loaded\", len(df)],\n",
        "        [\"Users\", df[\"user_id\"].nunique()],\n",
        "        [\"Days\", df[\"date\"].nunique()],\n",
        "        [\"Avg Heart Rate\", round(df[\"heart_rate\"].mean(), 1)],\n",
        "        [\"Start Date\", str(df[\"date\"].min().date())],\n",
        "        [\"End Date\", str(df[\"date\"].max().date())],\n",
        "    ]\n",
        "\n",
        "    overview_table = Table(overview_data)\n",
        "    overview_table.setStyle(TableStyle([\n",
        "        (\"BACKGROUND\", (0,0), (-1,0), colors.lightgrey),\n",
        "        (\"GRID\", (0,0), (-1,-1), 1, colors.black),\n",
        "        (\"FONT\", (0,0), (-1,0), \"Helvetica-Bold\"),\n",
        "    ]))\n",
        "\n",
        "    story.append(Paragraph(\"<b>Dataset Overview</b>\", styles[\"Heading2\"]))\n",
        "    story.append(Spacer(1, 10))\n",
        "    story.append(overview_table)\n",
        "    story.append(Spacer(1, 20))\n",
        "\n",
        "    # ---------- SAMPLE DATA ----------\n",
        "    story.append(Paragraph(\"<b>Sample Records</b>\", styles[\"Heading2\"]))\n",
        "    sample_table = df_to_table(df)\n",
        "    sample_table.setStyle(TableStyle([\n",
        "        (\"GRID\", (0,0), (-1,-1), 0.5, colors.grey),\n",
        "        (\"BACKGROUND\", (0,0), (-1,0), colors.whitesmoke),\n",
        "    ]))\n",
        "    story.append(sample_table)\n",
        "    story.append(Spacer(1, 20))\n",
        "\n",
        "    # ---------- ANOMALY SUMMARY ----------\n",
        "    if os.path.exists(\"anomaly_report.csv\"):\n",
        "        anom_df = pd.read_csv(\"anomaly_report.csv\")\n",
        "        story.append(Paragraph(\"<b>Anomaly Summary</b>\", styles[\"Heading2\"]))\n",
        "        anom_table = df_to_table(anom_df)\n",
        "        anom_table.setStyle(TableStyle([\n",
        "            (\"GRID\", (0,0), (-1,-1), 0.5, colors.grey),\n",
        "            (\"BACKGROUND\", (0,0), (-1,0), colors.lightgrey),\n",
        "        ]))\n",
        "        story.append(anom_table)\n",
        "        story.append(Spacer(1, 20))\n",
        "\n",
        "    # ---------- IMAGES ----------\n",
        "    story.append(Paragraph(\"<b>Visual Analytics</b>\", styles[\"Heading2\"]))\n",
        "    story.append(Spacer(1, 10))\n",
        "\n",
        "    image_files = (\n",
        "      glob.glob(\"prophet_heart_rate_*.png\") +\n",
        "      glob.glob(\"prophet_steps_*.png\") +\n",
        "      glob.glob(\"prophet_sleep_*.png\") +\n",
        "      [\"dbscan.png\", \"heart_rate_dist.png\", \"steps_dist.png\", \"sleep_dist.png\"]\n",
        "    )\n",
        "\n",
        "\n",
        "    for img in image_files:\n",
        "        if os.path.exists(img):\n",
        "            story.append(Image(img, width=400, height=220))\n",
        "            story.append(Spacer(1, 12))\n",
        "\n",
        "    # ---------- BUILD ----------\n",
        "    # ---------- RECOMMENDATIONS ----------\n",
        "    if os.path.exists(\"recommendations.csv\"):\n",
        "        rec_df = pd.read_csv(\"recommendations.csv\")\n",
        "        story.append(Paragraph(\"<b>Health Recommendations</b>\", styles[\"Heading2\"]))\n",
        "        rec_table = df_to_table(rec_df)\n",
        "        rec_table.setStyle(TableStyle([\n",
        "            (\"GRID\", (0,0), (-1,-1), 0.5, colors.grey),\n",
        "            (\"BACKGROUND\", (0,0), (-1,0), colors.lightgrey),\n",
        "        ]))\n",
        "        story.append(rec_table)\n",
        "        story.append(Spacer(1, 20))\n",
        "\n",
        "    doc.build(story)\n",
        "\n",
        "    return FileResponse(\n",
        "        filename,\n",
        "        media_type=\"application/pdf\",\n",
        "        filename=filename\n",
        "    )\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "I14jE5jjv7W5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "353bd3d1-3410-4185-a53f-4be2fb2665a9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing backend.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yUa7Fy5Yi63o"
      },
      "outputs": [],
      "source": [
        "import threading\n",
        "import uvicorn\n",
        "\n",
        "def run_backend():\n",
        "    uvicorn.run(\"backend:app\", host=\"0.0.0.0\", port=8003)\n",
        "\n",
        "threading.Thread(target=run_backend).start()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "backend_url = ngrok.connect(8003)\n",
        "print(\"BACKEND URL:\", backend_url)"
      ],
      "metadata": {
        "id": "ZsKGrZo9jJSb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dedf003-bf3e-4da7-d1e1-158f7d240591"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BACKEND URL: NgrokTunnel: \"https://renowned-zuri-coleopterous.ngrok-free.dev\" -> \"http://localhost:8003\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p .streamlit"
      ],
      "metadata": {
        "id": "zVLzc69wlzqt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile .streamlit/config.toml\n",
        "[theme]\n",
        "base=\"light\"\n",
        "primaryColor=\"#E63946\"\n",
        "backgroundColor=\"#F1FAEE\"\n",
        "secondaryBackgroundColor=\"#A8DADC\"\n",
        "textColor=\"#1D3557\""
      ],
      "metadata": {
        "id": "AibKm3_XmA3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb9af625-bd2f-4044-fcbb-e66e2f34c59d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing .streamlit/config.toml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import requests\n",
        "import io\n",
        "from datetime import datetime\n",
        "import plotly.express as px\n",
        "\n",
        "# ================= CONFIG =================\n",
        "BACKEND = \"http://localhost:8003\"\n",
        "HEADERS = {\"ngrok-skip-browser-warning\": \"true\"}\n",
        "\n",
        "st.set_page_config(\n",
        "    page_title=\"FitPulse Health Analytics\",\n",
        "    layout=\"wide\"\n",
        ")\n",
        "\n",
        "# ================= SESSION STATE =================\n",
        "if \"preprocess_done\" not in st.session_state:\n",
        "    st.session_state.preprocess_done = False\n",
        "\n",
        "if \"module2_done\" not in st.session_state:\n",
        "    st.session_state.module2_done = False\n",
        "\n",
        "# ================= API HELPERS =================\n",
        "def api_get(endpoint, raw=False):\n",
        "    r = requests.get(f\"{BACKEND}{endpoint}\", headers=HEADERS)\n",
        "\n",
        "    if raw:\n",
        "        return r\n",
        "\n",
        "    try:\n",
        "        return r.json()\n",
        "    except Exception:\n",
        "        st.error(f\"Backend returned invalid JSON for {endpoint}\")\n",
        "        st.text(r.text[:500])  # show first 500 chars\n",
        "        return {}\n",
        "\n",
        "\n",
        "def api_post(endpoint, files=None):\n",
        "    return requests.post(f\"{BACKEND}{endpoint}\", files=files, headers=HEADERS).json()\n",
        "\n",
        "def api_post_json(endpoint, payload=None):\n",
        "    r = requests.post(f\"{BACKEND}{endpoint}\", json=payload, headers=HEADERS)\n",
        "\n",
        "    if r.status_code != 200:\n",
        "        st.error(f\"Backend error {r.status_code}\")\n",
        "        st.text(r.text)\n",
        "        return {}\n",
        "\n",
        "    try:\n",
        "        return r.json()\n",
        "    except Exception:\n",
        "        st.error(\"Backend did not return JSON\")\n",
        "        st.text(r.text)\n",
        "        return {}\n",
        "\n",
        "\n",
        "\n",
        "# ================= COMMON FILTERS =================\n",
        "def sidebar_filters(metrics=True):\n",
        "    overview = api_get(\"/overview\")\n",
        "    users = [\"All\"]\n",
        "\n",
        "    try:\n",
        "        backend_users = overview.get(\"users_list\", [])\n",
        "        users += sorted([str(u) for u in backend_users])\n",
        "\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    user = st.sidebar.selectbox(\"Select User\", users)\n",
        "\n",
        "    try:\n",
        "        start = datetime.strptime(overview[\"start_date\"], \"%Y-%m-%d\")\n",
        "        end = datetime.strptime(overview[\"end_date\"], \"%Y-%m-%d\")\n",
        "    except:\n",
        "        start, end = datetime.today(), datetime.today()\n",
        "\n",
        "    dates = st.sidebar.date_input(\"Date Range\", [start, end])\n",
        "\n",
        "    metric = None\n",
        "    if metrics:\n",
        "        metric = st.sidebar.multiselect(\n",
        "            \"Select Metrics\",\n",
        "            [\"heart_rate\", \"steps\", \"sleep\"],\n",
        "            default=[\"heart_rate\", \"steps\", \"sleep\"]\n",
        "        )\n",
        "\n",
        "    return user, dates, metric\n",
        "\n",
        "# ================= SIDEBAR =================\n",
        "st.sidebar.title(\"FitPulse Controls\")\n",
        "\n",
        "page = st.sidebar.radio(\n",
        "    \"Navigation\",\n",
        "    [\n",
        "        \"1. Data Upload & Preprocessing\",\n",
        "        \"2. Feature Extraction\",\n",
        "        \"3. Trends\",\n",
        "        \"4. Anomalies\",\n",
        "        \"5. Distributions & DBSCAN\",\n",
        "        \"6. User Dashboard\",\n",
        "        \"7. Downloads\"\n",
        "    ]\n",
        ")\n",
        "\n",
        "st.sidebar.divider()\n",
        "@st.cache_data(show_spinner=False)\n",
        "def load_processed_data():\n",
        "    res = api_get(\"/dataframe\")\n",
        "    if not res or \"rows\" not in res:\n",
        "        return pd.DataFrame()\n",
        "    return pd.DataFrame(res[\"rows\"])\n",
        "\n",
        "# ================= LOAD PROCESSED DATA =================\n",
        "df = load_processed_data()\n",
        "st.session_state.df = df\n",
        "\n",
        "\n",
        "if not df.empty:\n",
        "    df[\"user_id\"] = df[\"user_id\"].astype(str)\n",
        "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
        "\n",
        "    # ---- column alignment with backend ----\n",
        "    if \"avg_heart_rate\" in df.columns:\n",
        "        df.rename(columns={\"avg_heart_rate\": \"heart_rate\"}, inplace=True)\n",
        "\n",
        "    if \"TotalSteps\" in df.columns:\n",
        "        df.rename(columns={\"TotalSteps\": \"steps\"}, inplace=True)\n",
        "\n",
        "    if \"total_sleep_minutes\" in df.columns:\n",
        "        df[\"sleep\"] = df[\"total_sleep_minutes\"] / 60\n",
        "\n",
        "\n",
        "# ================= PAGE ROUTER =================\n",
        "if page == \"1. Data Upload & Preprocessing\":\n",
        "    st.title(\"FitPulse Health Analytics\")\n",
        "    with st.expander(\"Project Overview\", expanded=True):\n",
        "        st.markdown(\"\"\"\n",
        "**FitPulse** is an end-to-end health analytics system for wearable data.\n",
        "\n",
        "**Input Columns**\n",
        "- user_id\n",
        "- date\n",
        "- TotalSteps\n",
        "- avg_heart_rate\n",
        "- total_sleep_minutes\n",
        "\n",
        "**Outputs**\n",
        "- Cleaned dataset\n",
        "- Rolling health features\n",
        "- Anomalies & clustering\n",
        "- Interactive trends\n",
        "- CSV & PDF reports\n",
        "        \"\"\")\n",
        "\n",
        "    uploaded = st.file_uploader(\"Upload file\", type=[\"csv\", \"json\"])\n",
        "    if st.button(\"Run Preprocessing\"):\n",
        "        if not uploaded:\n",
        "            st.warning(\"Please upload a file first\")\n",
        "        else:\n",
        "            res = api_post(\"/preprocess\", files={\"file\": uploaded})\n",
        "            if res.get(\"status\") == \"success\":\n",
        "                st.success(\"Preprocessing completed\")\n",
        "                st.session_state.preprocess_done = True\n",
        "\n",
        "                ov = res[\"overview\"]\n",
        "                c1, c2, c3, c4 = st.columns(4)\n",
        "                c1.metric(\"Records\", ov[\"rows_loaded\"])\n",
        "                c2.metric(\"Users\", ov[\"users\"])\n",
        "                c3.metric(\"Days\", ov[\"days\"])\n",
        "                c4.metric(\"Avg HR\", ov[\"avg_hr\"])\n",
        "\n",
        "                st.dataframe(pd.DataFrame(res[\"preview\"]), use_container_width=True)\n",
        "            else:\n",
        "                st.error(res)\n",
        "\n",
        "elif page == \"2. Feature Extraction\":\n",
        "\n",
        "    st.title(\"Feature Extraction\")\n",
        "\n",
        "\n",
        "    if not st.session_state.preprocess_done:\n",
        "        st.warning(\"Complete preprocessing first\")\n",
        "    else:\n",
        "        # ---------- RUN MODULE2 ONCE ----------\n",
        "        if not st.session_state.module2_done:\n",
        "            res = api_post_json(\"/module2\")\n",
        "            if res.get(\"status\") == \"success\":\n",
        "                st.success(\"Feature extraction completed\")\n",
        "                st.session_state.module2_done = True\n",
        "            else:\n",
        "                st.error(\"Module2 failed. Check backend logs.\")\n",
        "                st.stop()\n",
        "\n",
        "\n",
        "        # ---------- TSFRESH SECTION ----------\n",
        "        st.subheader(\"TSFRESH Feature Insights (Full Dataset)\")\n",
        "\n",
        "        ts = api_get(\"/module3/tsfresh-summary\")\n",
        "        df_ts = pd.DataFrame(ts.get(\"features\", []))\n",
        "\n",
        "        if df_ts.empty:\n",
        "            st.info(\"No TSFRESH features available\")\n",
        "        else:\n",
        "            st.success(\"TSFRESH feature extraction completed\")\n",
        "\n",
        "            # Chart\n",
        "            fig = px.bar(\n",
        "                df_ts,\n",
        "                x=\"description\",\n",
        "                y=\"importance\",\n",
        "                title=\"Key Behavioral Patterns (All Users)\",\n",
        "                labels={\"description\": \"Behavioral Insight\", \"importance\": \"Impact Level (log scale)\"}\n",
        "            )\n",
        "            fig.update_layout(xaxis_tickangle=-30)\n",
        "            st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "            # Table\n",
        "            st.dataframe(\n",
        "                df_ts.rename(columns={\"description\": \"Behavioral Insight\", \"importance\": \"Impact Level\"}),\n",
        "                use_container_width=True\n",
        "            )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "elif page == \"3. Trends\":\n",
        "    if not st.session_state.module2_done:\n",
        "        st.warning(\"Complete previous modules first\")\n",
        "    else:\n",
        "        st.title(\"Health Trends\")\n",
        "        user, _, metrics = sidebar_filters(metrics=True)\n",
        "\n",
        "        if not metrics:\n",
        "            st.warning(\"Select at least one metric\")\n",
        "        else:\n",
        "            for metric in metrics:\n",
        "                r = api_get(f\"/module3/prophet/{metric}?user_id={user}\", raw=True)\n",
        "                if r.status_code == 200:\n",
        "                    st.image(io.BytesIO(r.content), use_column_width=True)\n",
        "                else:\n",
        "                    st.error(r.json().get(\"error\", \"No data\"))\n",
        "\n",
        "elif page == \"4. Anomalies\":\n",
        "    if not st.session_state.module2_done:\n",
        "        st.warning(\"Complete previous modules first\")\n",
        "    else:\n",
        "        st.title(\"Anomaly Analysis\")\n",
        "        user, _, metrics = sidebar_filters(metrics=True)\n",
        "\n",
        "        # ------------------ Anomaly Summary ------------------\n",
        "        summary = api_get(f\"/module3/summary?user_id={user}\")\n",
        "        summary_dict = summary.get(\"summary\", {}) if isinstance(summary, dict) else {}\n",
        "\n",
        "        if not summary_dict:\n",
        "            st.info(\"No anomalies found for selected user.\")\n",
        "        else:\n",
        "            df_summary = pd.DataFrame(\n",
        "                summary_dict.items(),\n",
        "                columns=[\"Metric\", \"Count\"]\n",
        "            )\n",
        "\n",
        "            metric_map = {\n",
        "                \"heart_rate\": [\"heart_rate_high\", \"heart_rate_low\"],\n",
        "                \"steps\": [\"no_steps\"],\n",
        "                \"sleep\": [\"sleep_low\", \"sleep_high\"]\n",
        "            }\n",
        "\n",
        "            selected_metrics = []\n",
        "            if metrics:\n",
        "                for m in metrics:\n",
        "                    selected_metrics.extend(metric_map.get(m, []))\n",
        "\n",
        "            if selected_metrics:\n",
        "                df_summary_plot = df_summary[df_summary[\"Metric\"].isin(selected_metrics)]\n",
        "            else:\n",
        "                df_summary_plot = df_summary.copy()\n",
        "\n",
        "            if df_summary_plot.empty:\n",
        "                st.info(\"No anomalies found for selected metric filters.\")\n",
        "            else:\n",
        "                fig = px.bar(\n",
        "                    df_summary_plot,\n",
        "                    x=\"Metric\",\n",
        "                    y=\"Count\",\n",
        "                    color=\"Metric\",\n",
        "                    title=\"Anomaly Summary\"\n",
        "                )\n",
        "                st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "        # ------------------ Detailed Health Insights ------------------\n",
        "        st.subheader(\"Detailed Health Insights\")\n",
        "        combined_table = api_get(\n",
        "            f\"/module3/anomaly-with-recommendations?user_id={user}\"\n",
        "        )\n",
        "\n",
        "        rows = combined_table.get(\"rows\", []) if isinstance(combined_table, dict) else []\n",
        "\n",
        "        if rows:\n",
        "            df_combined = pd.DataFrame(rows)\n",
        "\n",
        "            # ✅ FIX: ensure user_id exists\n",
        "            if \"user_id\" not in df_combined.columns:\n",
        "                df_combined[\"user_id\"] = user\n",
        "\n",
        "            # Sort by severity\n",
        "            if \"severity\" in df_combined.columns:\n",
        "                severity_map = {\"High\": 3, \"Medium\": 2, \"Low\": 1}\n",
        "                df_combined[\"severity_rank\"] = df_combined[\"severity\"].map(severity_map)\n",
        "                df_combined = df_combined.sort_values(\n",
        "                    by=\"severity_rank\",\n",
        "                    ascending=False\n",
        "                )\n",
        "\n",
        "            display_cols = [\"user_id\", \"date\", \"issue\", \"severity\", \"recommendation\"]\n",
        "\n",
        "            st.dataframe(\n",
        "                df_combined[display_cols],\n",
        "                use_container_width=True,\n",
        "                height=380\n",
        "            )\n",
        "\n",
        "            # Download CSV\n",
        "            csv = df_combined[display_cols].to_csv(index=False).encode(\"utf-8\")\n",
        "\n",
        "            st.download_button(\n",
        "                \"Download Detailed Insights\",\n",
        "                csv,\n",
        "                f\"user_{user}_health_insights.csv\"\n",
        "            )\n",
        "        else:\n",
        "            st.info(\"No detailed health insights available for this user.\")\n",
        "\n",
        "\n",
        "\n",
        "elif page == \"5. Distributions & DBSCAN\":\n",
        "    if not st.session_state.module2_done:\n",
        "        st.warning(\"Complete previous modules first\")\n",
        "    else:\n",
        "        st.title(\"Distributions & Clustering\")\n",
        "        user, _, metrics = sidebar_filters(metrics=True)\n",
        "\n",
        "        for metric in metrics:\n",
        "            r = api_get(f\"/module3/distribution/{metric}?user_id={user}\", raw=True)\n",
        "            if r.status_code == 200:\n",
        "                st.image(io.BytesIO(r.content), caption=f\"{metric} distribution\", use_column_width=True)\n",
        "\n",
        "        if any(m in metrics for m in [\"heart_rate\", \"steps\", \"sleep\"]):\n",
        "            r = api_get(f\"/module3/dbscan?user_id={user}\", raw=True)\n",
        "            if r.status_code == 200:\n",
        "                st.image(io.BytesIO(r.content), caption=\"DBSCAN clustering\", use_column_width=True)\n",
        "\n",
        "# ================= PAGE 6 : USER HEALTH DASHBOARD =================\n",
        "elif page == \"6. User Dashboard\":\n",
        "    st.title(\"User Health Dashboard\")\n",
        "\n",
        "    # ---------------- LOAD USER DATA ----------------\n",
        "    df = st.session_state.get(\"df\", pd.DataFrame())\n",
        "    if df.empty:\n",
        "        res = api_get(\"/dataframe\")\n",
        "        if \"rows\" in res and res[\"rows\"]:\n",
        "            df = pd.DataFrame(res[\"rows\"])\n",
        "            df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
        "            st.session_state.df = df\n",
        "        else:\n",
        "            st.warning(\"No processed data available. Run preprocessing first.\")\n",
        "            st.stop()\n",
        "\n",
        "    # ---------------- SELECT USER ----------------\n",
        "    user_ids = df[\"user_id\"].unique() if \"user_id\" in df.columns else [\"Demo User\"]\n",
        "    selected_user = st.selectbox(\"Select User\", user_ids)\n",
        "\n",
        "    # ✅ THIS LINE FIXES EVERYTHING\n",
        "    st.session_state.selected_user = selected_user\n",
        "\n",
        "    user_data = df[df[\"user_id\"] == selected_user].copy()\n",
        "\n",
        "\n",
        "    if user_data.empty:\n",
        "        st.warning(\"No data available for this user.\")\n",
        "        st.stop()\n",
        "\n",
        "    # ---------------- MERGE ANOMALIES ----------------\n",
        "    anom = api_get(f\"/module3/anomaly-with-recommendations?user_id={selected_user}\")\n",
        "    anom_rows = anom.get(\"rows\", [])\n",
        "    if anom_rows:\n",
        "        df_anom = pd.DataFrame(anom_rows)\n",
        "        df_anom[\"date\"] = pd.to_datetime(df_anom[\"date\"])\n",
        "        user_data = user_data.merge(\n",
        "            df_anom[[\"date\", \"issue\", \"severity\", \"recommendation\"]],\n",
        "            on=\"date\",\n",
        "            how=\"left\"\n",
        "        )\n",
        "    else:\n",
        "        user_data[\"issue\"] = None\n",
        "        user_data[\"severity\"] = None\n",
        "        user_data[\"recommendation\"] = None\n",
        "\n",
        "    # ---------------- ROW 1: Key Metrics ----------------\n",
        "    avg_heart = round(user_data[\"heart_rate\"].mean(), 1)\n",
        "    avg_steps = round(user_data[\"steps\"].mean(), 0)\n",
        "    avg_sleep = round(user_data[\"sleep\"].mean(), 1)\n",
        "\n",
        "    # ---------------- HEALTH SCORE (Continuous) ----------------\n",
        "    health_data = api_get(f\"/module3/health-score?user_id={selected_user}\")\n",
        "\n",
        "    if health_data:\n",
        "        health_score = health_data.get(\"health_score\", 0)\n",
        "        hr_score = health_data[\"components\"][\"heart_rate\"]\n",
        "        steps_score = health_data[\"components\"][\"steps\"]\n",
        "        sleep_score = health_data[\"components\"][\"sleep\"]\n",
        "    else:\n",
        "        health_score = 0\n",
        "        hr_score = steps_score = sleep_score = 0\n",
        "\n",
        "    col1, col2, col3, col4 = st.columns(4)\n",
        "    col1.metric(\"Avg Heart Rate (BPM)\", avg_heart)\n",
        "    col2.metric(\"Avg Steps\", avg_steps)\n",
        "    col3.metric(\"Avg Sleep (hrs)\", avg_sleep)\n",
        "    col4.metric(\"Health Score (%)\", health_score)\n",
        "\n",
        "    # ---------------- ROW 2: Health Status & Table Side by Side ----------------\n",
        "    # ---------------- ROW 2: Health Status & Table Side by Side ----------------\n",
        "    st.subheader(\"Health Status & User Issues\")\n",
        "    col1, col2 = st.columns(2)\n",
        "\n",
        "    # --- Donut chart for Health Status ---\n",
        "    import plotly.graph_objects as go\n",
        "\n",
        "    fig_donut = go.Figure(data=[go.Pie(\n",
        "        labels=[\"Heart Rate\", \"Steps\", \"Sleep\"],\n",
        "        values=[hr_score, steps_score, sleep_score],\n",
        "        hole=0.6,\n",
        "        textinfo=\"label+percent\",\n",
        "        marker=dict(colors=[\"crimson\", \"royalblue\", \"green\"])\n",
        "    )])\n",
        "\n",
        "    fig_donut.update_layout(\n",
        "        title=f\"{selected_user} Health Score\",\n",
        "        annotations=[dict(\n",
        "            text=f\"{health_score}%\",\n",
        "            x=0.5, y=0.5,\n",
        "            font_size=22,\n",
        "            showarrow=False\n",
        "        )],\n",
        "        margin=dict(t=50, b=20, l=20, r=20)\n",
        "    )\n",
        "\n",
        "    # 👈 THIS was missing\n",
        "    col1.plotly_chart(fig_donut, use_container_width=True)\n",
        "\n",
        "    # --- Table for user data ---\n",
        "    display_cols = [\"date\", \"heart_rate\", \"steps\", \"sleep\"]\n",
        "    if \"issue\" in user_data.columns:\n",
        "        display_cols += [\"issue\", \"severity\", \"recommendation\"]\n",
        "\n",
        "    col2.dataframe(\n",
        "        user_data[display_cols].sort_values(\"date\", ascending=False),\n",
        "        use_container_width=True\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "    # ---------------- ROW 3: Raw vs Rolling Metrics ----------------\n",
        "    st.subheader(\"Trends: Raw vs Rolling Average\")\n",
        "    metrics = [\"heart_rate\", \"steps\", \"sleep\"]\n",
        "    for metric in metrics:\n",
        "        if metric in user_data.columns:\n",
        "            user_data[f\"{metric}_rolling\"] = user_data[metric].rolling(3, min_periods=1).mean()\n",
        "            fig = px.line(user_data, x=\"date\", y=[metric, f\"{metric}_rolling\"],\n",
        "                          labels={\"value\": metric, \"variable\": \"Type\"},\n",
        "                          title=f\"{metric.replace('_',' ').title()} (Raw vs Rolling)\")\n",
        "            st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "    # ---------------- ROW 4: DBSCAN Clusters ----------------\n",
        "    st.subheader(\"Activity Clusters (DBSCAN)\")\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    from sklearn.cluster import DBSCAN\n",
        "\n",
        "    cluster_cols = [\"heart_rate\", \"steps\", \"sleep\"]\n",
        "    if all(col in user_data.columns for col in cluster_cols):\n",
        "        X = StandardScaler().fit_transform(user_data[cluster_cols])\n",
        "        db = DBSCAN(eps=1.5, min_samples=2).fit(X)\n",
        "        user_data[\"cluster\"] = db.labels_\n",
        "        fig = px.scatter_3d(user_data, x=\"heart_rate\", y=\"steps\", z=\"sleep\",\n",
        "                            color=\"cluster\", title=\"DBSCAN Clusters\")\n",
        "        st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "\n",
        "\n",
        "    # =================================================\n",
        "    # USER-SPECIFIC REPORT GENERATION\n",
        "    # =================================================\n",
        "\n",
        "elif page == \"7. Downloads\":\n",
        "    st.title(\"Download Reports\")\n",
        "\n",
        "    # ---------- FULL DASHBOARD PDF ----------\n",
        "    st.subheader(\"Full Dashboard PDF\")\n",
        "\n",
        "    st.markdown(\"\"\"\n",
        "    This PDF contains:\n",
        "    - Dataset Overview\n",
        "    - Sample Records\n",
        "    - Anomaly Summary\n",
        "    - Health Metrics\n",
        "    - Visual Analytics\n",
        "    - Recommendations\n",
        "    \"\"\")\n",
        "\n",
        "    if st.button(\"Generate & Download Full Dashboard PDF\"):\n",
        "        r = requests.get(f\"{BACKEND}/download-report\", headers=HEADERS)\n",
        "        if r.status_code == 200:\n",
        "            st.download_button(\n",
        "                \"Download Full Dashboard PDF\",\n",
        "                r.content,\n",
        "                file_name=\"fitpulse_dashboard_report.pdf\",\n",
        "                mime=\"application/pdf\"\n",
        "            )\n",
        "        else:\n",
        "            st.error(\"Failed to generate full dashboard PDF\")\n",
        "\n",
        "    # ---------- PERSONALIZED USER PDF ----------\n",
        "    st.subheader(\"Personalized User Report\")\n",
        "\n",
        "    selected_user = st.session_state.get(\"selected_user\")\n",
        "\n",
        "    if not selected_user:\n",
        "        st.warning(\"Please select a user from the Dashboard page first.\")\n",
        "    else:\n",
        "        if st.button(\"Generate User Dashboard PDF\"):\n",
        "            r = requests.get(\n",
        "                f\"{BACKEND}/module4/user-dashboard-report?user_id={selected_user}\",\n",
        "                headers=HEADERS\n",
        "            )\n",
        "\n",
        "            if r.status_code == 200:\n",
        "                st.download_button(\n",
        "                    \"Download User PDF\",\n",
        "                    r.content,\n",
        "                    file_name=f\"user_{selected_user}_dashboard.pdf\",\n",
        "                    mime=\"application/pdf\"\n",
        "                )\n",
        "            else:\n",
        "                st.error(\"Failed to generate personalized report\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "st.caption(\"FitPulse | FastAPI Backend with Streamlit Frontend\")"
      ],
      "metadata": {
        "id": "-jNGlnLYOmxw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31b8cf1a-fb5c-451a-816e-77239f3de8d8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py --server.port 8501 --server.address 0.0.0.0"
      ],
      "metadata": {
        "id": "z6Bz5WMJjOIu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2561439e-3bad-4f90-800b-f068f3dd21e3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  URL: \u001b[0m\u001b[1mhttp://0.0.0.0:8501\u001b[0m\n",
            "\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2026-01-26T16:42:36+0000 lvl=warn msg=\"Stopping forwarder\" name=http-8003-5b776319-6c8e-4eb0-b3d5-44aba8f82ce0 acceptErr=\"failed to accept connection: Listener closed\"\n",
            "WARNING:pyngrok.process.ngrok:t=2026-01-26T16:42:36+0000 lvl=warn msg=\"Error restarting forwarder\" name=http-8003-5b776319-6c8e-4eb0-b3d5-44aba8f82ce0 err=\"failed to start tunnel: session closed\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# Launch Streamlit via Ngrok\n",
        "# ===============================\n",
        "import threading, time\n",
        "def run_streamlit():\n",
        "    !streamlit run app.py --server.port 8501 --server.address 0.0.0.0\n",
        "threading.Thread(target=run_streamlit).start()\n",
        "time.sleep(5)\n",
        "streamlit_url = ngrok.connect(8501)\n",
        "print(\"Streamlit public URL:\", streamlit_url)"
      ],
      "metadata": {
        "id": "637cjqQhjVBN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a261ae93-685d-4a8b-99dc-41699623f39d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  URL: \u001b[0m\u001b[1mhttp://0.0.0.0:8501\u001b[0m\n",
            "\u001b[0m\n",
            "Streamlit public URL: NgrokTunnel: \"https://renowned-zuri-coleopterous.ngrok-free.dev\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    }
  ]
}
