{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWvSCfJRiLi5"
      },
      "outputs": [],
      "source": [
        "# ===================== INSTALL REQUIRED PACKAGES =====================\n",
        "!pip install fastapi uvicorn pyngrok pandas numpy prophet scikit-learn tsfresh matplotlib plotly streamlit requests openai typing Optional reportlab --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCqiYAjEipQ-"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "# ngrok.set_auth_token(\"38R1JP7kNn7VgVq2lhBv8Dfd3cm_3nMAW2KpZWRyoWZpqL4uf\")\n",
        "ngrok.set_auth_token(\"380ZzaoDdXGvfjMya7VVYPbpJA4_3dcMEvWNppZQDdUGs9j7p\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"api_key\"\n",
        "!uvicorn backend:app --host 0.0.0.0 --port 8003"
      ],
      "metadata": {
        "id": "rlKUqqDT1KO5",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81977b86-1a57-4c66-e1a5-bcd65743e079"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32mINFO\u001b[0m:     Started server process [\u001b[36m43470\u001b[0m]\n",
            "\u001b[32mINFO\u001b[0m:     Waiting for application startup.\n",
            "\u001b[32mINFO\u001b[0m:     Application startup complete.\n",
            "\u001b[31mERROR\u001b[0m:    [Errno 98] error while attempting to bind on address ('0.0.0.0', 8003): address already in use\n",
            "\u001b[32mINFO\u001b[0m:     Waiting for application shutdown.\n",
            "\u001b[32mINFO\u001b[0m:     Application shutdown complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile backend.py\n",
        "from fastapi import FastAPI, UploadFile, File\n",
        "from fastapi.responses import JSONResponse, FileResponse\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "import pandas as pd\n",
        "from prophet import Prophet\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import DBSCAN\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from reportlab.platypus import (\n",
        "    SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, Image\n",
        ")\n",
        "from reportlab.lib.styles import getSampleStyleSheet\n",
        "from reportlab.lib.pagesizes import A4\n",
        "from reportlab.lib import colors\n",
        "from datetime import datetime\n",
        "import glob\n",
        "from openai import OpenAI\n",
        "\n",
        "\n",
        "from fastapi import Body\n",
        "from typing import Optional\n",
        "\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "if not api_key:\n",
        "    raise RuntimeError(\"OPENAI_API_KEY not set\")\n",
        "\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "\n",
        "# ================= APP =================\n",
        "app = FastAPI(title=\"FitPulse Backend\")\n",
        "\n",
        "# ================= CORS =================\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "# ================= GLOBAL STATE =================\n",
        "CLEAN_DF = None\n",
        "FEATURE_DF = None\n",
        "ANOMALY_DF = None\n",
        "RULE_RECOMMENDATIONS = None\n",
        "\n",
        "# ================= ROOT =================\n",
        "def classify_severity(count: int):\n",
        "    if count >= 20:\n",
        "        return \"High\"\n",
        "    elif count >= 5:\n",
        "        return \"Medium\"\n",
        "    return \"Low\"\n",
        "\n",
        "def df_to_table(df, max_rows=10):\n",
        "    data = [df.columns.tolist()] + df.head(max_rows).values.tolist()\n",
        "    return Table(data, repeatRows=1)\n",
        "\n",
        "@app.get(\"/\")\n",
        "def root():\n",
        "    return {\"message\": \"FitPulse Backend is running\"}\n",
        "\n",
        "# ================= PREPROCESSING (CSV + JSON) =================\n",
        "@app.post(\"/preprocess\")\n",
        "async def preprocess(file: UploadFile = File(...)):\n",
        "    global CLEAN_DF\n",
        "\n",
        "    try:\n",
        "        if file.filename.endswith(\".csv\"):\n",
        "            df = pd.read_csv(file.file)\n",
        "        elif file.filename.endswith(\".json\"):\n",
        "            df = pd.read_json(file.file)\n",
        "        else:\n",
        "            return JSONResponse(status_code=400, content={\"error\": \"Only CSV or JSON supported\"})\n",
        "    except Exception as e:\n",
        "        return JSONResponse(status_code=400, content={\"error\": f\"Invalid file: {e}\"})\n",
        "\n",
        "    required_cols = [\"user_id\", \"date\", \"TotalSteps\", \"avg_heart_rate\", \"total_sleep_minutes\"]\n",
        "    missing = [c for c in required_cols if c not in df.columns]\n",
        "    if missing:\n",
        "        return JSONResponse(status_code=400, content={\"error\": f\"Missing columns: {missing}\"})\n",
        "\n",
        "    # ---------- CLEANING ----------\n",
        "    df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
        "    for col in [\"TotalSteps\", \"avg_heart_rate\", \"total_sleep_minutes\"]:\n",
        "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "\n",
        "    df[\"TotalSteps\"].fillna(0, inplace=True)\n",
        "    df[\"avg_heart_rate\"].fillna(df[\"avg_heart_rate\"].median(), inplace=True)\n",
        "    df[\"total_sleep_minutes\"].fillna(df[\"total_sleep_minutes\"].median(), inplace=True)\n",
        "\n",
        "    # ---------- AGGREGATE ----------\n",
        "    df = df.groupby([\"user_id\", \"date\"], as_index=False).agg({\n",
        "        \"TotalSteps\": \"sum\",\n",
        "        \"avg_heart_rate\": \"mean\",\n",
        "        \"total_sleep_minutes\": \"mean\"\n",
        "    })\n",
        "\n",
        "    # ---------- RENAME FOR UI ----------\n",
        "    df.rename(columns={\n",
        "        \"avg_heart_rate\": \"heart_rate\",\n",
        "        \"TotalSteps\": \"steps\",\n",
        "        \"total_sleep_minutes\": \"sleep\"\n",
        "    }, inplace=True)\n",
        "\n",
        "    # Convert sleep minutes â†’ hours (matches screenshot ~7.05)\n",
        "    df[\"sleep\"] = (df[\"sleep\"] / 60).round(2)\n",
        "\n",
        "    CLEAN_DF = df\n",
        "    df.to_csv(\"clean_data.csv\", index=False)\n",
        "\n",
        "\n",
        "    return {\n",
        "        \"status\": \"success\",\n",
        "        \"overview\": {\n",
        "            \"rows_loaded\": len(df),\n",
        "            \"users\": df[\"user_id\"].nunique(),\n",
        "            \"days\": df[\"date\"].nunique(),\n",
        "            \"avg_hr\": round(df[\"heart_rate\"].mean(), 1)\n",
        "        },\n",
        "        \"preview\": df.head(20).to_dict(orient=\"records\")\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "# ================= OVERVIEW =================\n",
        "@app.get(\"/overview\")\n",
        "def overview():\n",
        "    if CLEAN_DF is None:\n",
        "        return {\"error\": \"Run /preprocess first\"}\n",
        "    df = CLEAN_DF\n",
        "    return {\n",
        "        \"rows\": len(df),\n",
        "        \"users_count\": df[\"user_id\"].nunique(),\n",
        "        \"users_list\": df[\"user_id\"].astype(str).unique().tolist(),  # <-- add this\n",
        "        \"start_date\": str(df[\"date\"].min().date()),\n",
        "        \"end_date\": str(df[\"date\"].max().date()),\n",
        "        \"avg_heart_rate\": round(df[\"heart_rate\"].mean(), 2),\n",
        "        \"avg_steps\": round(df[\"steps\"].mean(), 2),\n",
        "        \"avg_sleep_hours\": round(df[\"sleep\"].mean(), 2),\n",
        "    }\n",
        "\n",
        "# ================= FEATURES + ANOMALIES =================\n",
        "@app.post(\"/module2\")\n",
        "def module2():\n",
        "    global FEATURE_DF, ANOMALY_DF, RULE_RECOMMENDATIONS\n",
        "    if CLEAN_DF is None:\n",
        "        return JSONResponse(status_code=400, content={\"error\": \"Run /preprocess first\"})\n",
        "\n",
        "    df = CLEAN_DF.copy().sort_values(\"date\")\n",
        "\n",
        "\n",
        "    FEATURE_DF = df.copy()\n",
        "\n",
        "    # Rolling 7-day mean features\n",
        "    for col in [\"steps\", \"heart_rate\", \"sleep\"]:\n",
        "        FEATURE_DF[f\"{col}_mean_7\"] = FEATURE_DF[col].rolling(7).mean()\n",
        "        FEATURE_DF[f\"{col}_std_7\"] = FEATURE_DF[col].rolling(7).std()\n",
        "        FEATURE_DF[f\"{col}_skew_7\"] = FEATURE_DF[col].rolling(7).skew()\n",
        "        FEATURE_DF[f\"{col}_kurt_7\"] = FEATURE_DF[col].rolling(7).kurt()\n",
        "\n",
        "    FEATURE_DF.to_csv(\"feature_data.csv\", index=False)\n",
        "\n",
        "    # Rule-based anomalies\n",
        "    records = []\n",
        "    for _, r in df.iterrows():\n",
        "        if r[\"heart_rate\"] > 120: records.append((r[\"user_id\"], r[\"date\"], \"heart_rate_high\"))\n",
        "        if r[\"heart_rate\"] < 40: records.append((r[\"user_id\"], r[\"date\"], \"heart_rate_low\"))\n",
        "        if r[\"steps\"] == 0: records.append((r[\"user_id\"], r[\"date\"], \"no_steps\"))\n",
        "        if r[\"sleep\"] < 4 or r[\"sleep\"] > 12: records.append((r[\"user_id\"], r[\"date\"], \"sleep_abnormal\"))\n",
        "\n",
        "    rule_df = pd.DataFrame(records, columns=[\"user_id\", \"date\", \"metric\"])\n",
        "\n",
        "    # DBSCAN anomalies\n",
        "    X_scaled = StandardScaler().fit_transform(df[[\"heart_rate\", \"steps\", \"sleep\"]])\n",
        "    labels = DBSCAN(eps=1.2, min_samples=3).fit_predict(X_scaled)\n",
        "    df[\"cluster\"] = labels\n",
        "    dbscan_df = df[df[\"cluster\"] == -1][[\"user_id\", \"date\"]].copy()\n",
        "    dbscan_df[\"metric\"] = \"dbscan_outlier\"\n",
        "\n",
        "    ANOMALY_DF = pd.concat([rule_df, dbscan_df], ignore_index=True)\n",
        "\n",
        "    summary_df = (\n",
        "        ANOMALY_DF\n",
        "        .groupby([\"user_id\", \"metric\"])\n",
        "        .size()\n",
        "        .reset_index(name=\"count\")\n",
        "    )\n",
        "\n",
        "    summary_df[\"severity\"] = summary_df[\"count\"].apply(classify_severity)\n",
        "\n",
        "    # Save both versions\n",
        "    ANOMALY_DF.to_csv(\"anomaly_raw.csv\", index=False)\n",
        "    summary_df.to_csv(\"anomaly_report.csv\", index=False)\n",
        "\n",
        "\n",
        "    recs = []\n",
        "\n",
        "    for _, row in summary_df.iterrows():\n",
        "        user = row[\"user_id\"]\n",
        "        metric = row[\"metric\"]\n",
        "        severity = row[\"severity\"]\n",
        "\n",
        "        if metric == \"heart_rate_high\":\n",
        "            recs.append({\n",
        "                \"user_id\": user,\n",
        "                \"issue\": \"High heart rate\",\n",
        "                \"severity\": severity,\n",
        "                \"recommendation\": \"Reduce high-intensity workouts and consult a physician if persistent.\"\n",
        "            })\n",
        "\n",
        "        elif metric == \"heart_rate_low\":\n",
        "            recs.append({\n",
        "                \"user_id\": user,\n",
        "                \"issue\": \"Low heart rate\",\n",
        "                \"severity\": severity,\n",
        "                \"recommendation\": \"Ensure adequate nutrition and consult a healthcare professional.\"\n",
        "            })\n",
        "\n",
        "        elif metric == \"no_steps\":\n",
        "            recs.append({\n",
        "                \"user_id\": user,\n",
        "                \"issue\": \"No physical activity\",\n",
        "                \"severity\": severity,\n",
        "                \"recommendation\": \"Increase daily movement with light walks or stretching.\"\n",
        "            })\n",
        "\n",
        "        elif metric == \"sleep_abnormal\":\n",
        "            recs.append({\n",
        "                \"user_id\": user,\n",
        "                \"issue\": \"Abnormal sleep duration\",\n",
        "                \"severity\": severity,\n",
        "                \"recommendation\": \"Maintain a consistent sleep schedule and improve sleep hygiene.\"\n",
        "            })\n",
        "\n",
        "        elif metric == \"dbscan_outlier\":\n",
        "            recs.append({\n",
        "                \"user_id\": user,\n",
        "                \"issue\": \"Unusual health pattern\",\n",
        "                \"severity\": severity,\n",
        "                \"recommendation\": \"Monitor trends closely; consider lifestyle adjustments.\"\n",
        "            })\n",
        "\n",
        "    RULE_RECOMMENDATIONS = pd.DataFrame(recs)\n",
        "    RULE_RECOMMENDATIONS.to_csv(\"recommendations.csv\", index=False)\n",
        "\n",
        "    return {\n",
        "        \"status\": \"success\",\n",
        "        \"total_anomalies\": len(ANOMALY_DF),\n",
        "        \"summary_rows\": len(summary_df)\n",
        "    }\n",
        "\n",
        "\n",
        "# ================= ANOMALY SUMMARY =================\n",
        "\n",
        "@app.get(\"/module3/summary\")\n",
        "def anomaly_summary(user_id: str = \"All\"):\n",
        "    if ANOMALY_DF is None or ANOMALY_DF.empty:\n",
        "        return {\"summary\": {}}\n",
        "\n",
        "    df = ANOMALY_DF.copy()\n",
        "    df[\"user_id\"] = df[\"user_id\"].astype(str)\n",
        "\n",
        "    if user_id != \"All\":\n",
        "        df = df[df[\"user_id\"] == user_id]\n",
        "\n",
        "    return {\"summary\": df[\"metric\"].value_counts().to_dict()}\n",
        "\n",
        "\n",
        "# ================= PROPHET PLOTS =================\n",
        "def plot_prophet(df, column, fname, ylabel):\n",
        "    df2 = df[[\"date\", column]].rename(columns={\"date\":\"ds\", column:\"y\"})\n",
        "    if len(df2) < 10: return None\n",
        "    model = Prophet()\n",
        "    model.fit(df2)\n",
        "    forecast = model.predict(df2)\n",
        "    df2[\"yhat\"] = forecast[\"yhat\"]\n",
        "    df2[\"residual\"] = df2[\"y\"] - df2[\"yhat\"]\n",
        "    threshold = 2.5 * df2[\"residual\"].std()\n",
        "    outliers = df2[abs(df2[\"residual\"]) > threshold]\n",
        "\n",
        "    plt.figure(figsize=(12,5))\n",
        "    plt.plot(df2[\"ds\"], df2[\"y\"], label=f\"Actual {ylabel}\",color=\"blue\")\n",
        "    plt.plot(df2[\"ds\"], df2[\"yhat\"], label=\"Prophet Trend\",color=\"red\")\n",
        "    plt.scatter(outliers[\"ds\"], outliers[\"y\"], color=\"red\", label=\"Anomaly\")\n",
        "    plt.xlabel(\"Date\")\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.title(f\"{ylabel} Prophet Trend Anomalies\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(fname)\n",
        "    plt.close()\n",
        "    return fname\n",
        "@app.get(\"/module3/anomaly-table\")\n",
        "def anomaly_table():\n",
        "    if not os.path.exists(\"anomaly_report.csv\"):\n",
        "        return JSONResponse(status_code=404, content={\"error\": \"Run anomaly detection first\"})\n",
        "\n",
        "    df = pd.read_csv(\"anomaly_report.csv\")\n",
        "    return {\n",
        "        \"rows\": df.to_dict(orient=\"records\")\n",
        "    }\n",
        "@app.get(\"/module3/prophet/{metric}\")\n",
        "def prophet_metric(metric: str, user_id: str = \"All\"):\n",
        "    mapping = {\n",
        "        \"heart_rate\": \"Heart Rate (BPM)\",\n",
        "        \"steps\": \"Steps\",\n",
        "        \"sleep\": \"Sleep (Hours)\"\n",
        "    }\n",
        "\n",
        "    if FEATURE_DF is None:\n",
        "        return JSONResponse(status_code=400, content={\"error\": \"Run /module2 first\"})\n",
        "\n",
        "    if metric not in mapping:\n",
        "        return JSONResponse(status_code=400, content={\"error\": \"Invalid metric\"})\n",
        "\n",
        "    # âœ… FORCE STRING TYPES (THIS IS THE KEY FIX)\n",
        "    df = FEATURE_DF.copy()\n",
        "    df[\"user_id\"] = df[\"user_id\"].astype(str)\n",
        "    user_id = str(user_id)\n",
        "\n",
        "    # âœ… APPLY USER FILTER\n",
        "    if user_id != \"All\":\n",
        "        df = df[df[\"user_id\"] == user_id]\n",
        "\n",
        "    if df.empty:\n",
        "        return JSONResponse(status_code=400, content={\"error\": \"No data for selected user\"})\n",
        "\n",
        "    fname = f\"prophet_{metric}.png\"\n",
        "\n",
        "    # âœ… PASS FILTERED DATA ONLY\n",
        "    if plot_prophet(df, metric, fname, mapping[metric]):\n",
        "        return FileResponse(fname)\n",
        "\n",
        "    return JSONResponse(status_code=400, content={\"error\": \"Not enough data\"})\n",
        "\n",
        "\n",
        "\n",
        "# ================= DBSCAN VISUALIZATION =================\n",
        "# ================= DBSCAN VISUALIZATION =================\n",
        "@app.get(\"/module3/dbscan\")\n",
        "def dbscan_viz(user_id: str = \"All\"):\n",
        "    if FEATURE_DF is None:\n",
        "        return JSONResponse(status_code=400, content={\"error\": \"Run /module2 first\"})\n",
        "\n",
        "    df = FEATURE_DF.copy()\n",
        "    df[\"user_id\"] = df[\"user_id\"].astype(str)\n",
        "\n",
        "    if user_id != \"All\":\n",
        "        df = df[df[\"user_id\"] == user_id]\n",
        "\n",
        "    if df.empty:\n",
        "        return JSONResponse(status_code=400, content={\"error\": \"No data for selected user\"})\n",
        "\n",
        "    X_scaled = StandardScaler().fit_transform(df[[\"heart_rate\", \"steps\", \"sleep\"]])\n",
        "    labels = DBSCAN(eps=1.2, min_samples=3).fit_predict(X_scaled)\n",
        "    df[\"cluster\"] = labels\n",
        "\n",
        "    normal = df[df[\"cluster\"] != -1]\n",
        "    outliers = df[df[\"cluster\"] == -1]\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.scatter(normal[\"steps\"], normal[\"heart_rate\"], label=\"Normal\", alpha=0.6)\n",
        "    plt.scatter(outliers[\"steps\"], outliers[\"heart_rate\"], label=\"Outlier\", alpha=0.9)\n",
        "\n",
        "    plt.xlabel(\"Steps\")\n",
        "    plt.ylabel(\"Heart Rate\")\n",
        "    plt.title(\"DBSCAN Clustering\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    fname = \"dbscan.png\"\n",
        "    plt.savefig(fname)\n",
        "    plt.close()\n",
        "\n",
        "    return FileResponse(fname)\n",
        "\n",
        "\n",
        "# ================= DISTRIBUTION =================\n",
        "# ================= DISTRIBUTION =================\n",
        "@app.get(\"/module3/distribution/{metric}\")\n",
        "def distribution(metric: str, user_id: str = \"All\"):\n",
        "    if FEATURE_DF is None:\n",
        "        return JSONResponse(status_code=400, content={\"error\": \"Run /module2 first\"})\n",
        "\n",
        "    if metric not in [\"heart_rate\", \"steps\", \"sleep\"]:\n",
        "        return JSONResponse(status_code=400, content={\"error\": \"Invalid metric\"})\n",
        "\n",
        "    df = FEATURE_DF.copy()\n",
        "    df[\"user_id\"] = df[\"user_id\"].astype(str)\n",
        "\n",
        "    if user_id != \"All\":\n",
        "        df = df[df[\"user_id\"] == user_id]\n",
        "\n",
        "    if df.empty:\n",
        "        return JSONResponse(status_code=400, content={\"error\": \"No data for selected user\"})\n",
        "\n",
        "    colors_map = {\n",
        "        \"heart_rate\": \"crimson\",\n",
        "        \"steps\": \"royalblue\",\n",
        "        \"sleep\": \"green\"\n",
        "    }\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.hist(df[metric], bins=20, color=colors_map[metric], edgecolor=\"black\")\n",
        "    plt.xlabel(metric)\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.title(f\"{metric} Distribution\")\n",
        "    plt.grid(True)\n",
        "\n",
        "    fname = f\"{metric}_dist.png\"\n",
        "    plt.savefig(fname)\n",
        "    plt.close()\n",
        "\n",
        "    return FileResponse(fname)\n",
        "\n",
        "\n",
        "@app.get(\"/recommendations\")\n",
        "def get_recommendations(user_id: str = \"All\"):\n",
        "    if RULE_RECOMMENDATIONS is None or RULE_RECOMMENDATIONS.empty:\n",
        "        return {\"message\": \"No rule-based recommendations available\"}\n",
        "\n",
        "    df = RULE_RECOMMENDATIONS.copy()\n",
        "    df[\"user_id\"] = df[\"user_id\"].astype(str)\n",
        "\n",
        "    if user_id != \"All\":\n",
        "        df = df[df[\"user_id\"] == user_id]\n",
        "\n",
        "    return df.to_dict(orient=\"records\")\n",
        "\n",
        "\n",
        "# ================= DOWNLOAD ANOMALIES =================\n",
        "@app.get(\"/download-anomalies\")\n",
        "def download_anomalies():\n",
        "    if not os.path.exists(\"anomaly_report.csv\"):\n",
        "        return JSONResponse(status_code=404, content={\"error\": \"No anomalies\"})\n",
        "\n",
        "    return FileResponse(\n",
        "        \"anomaly_report.csv\",\n",
        "        media_type=\"text/csv\",\n",
        "        filename=\"anomaly_report.csv\"\n",
        "    )\n",
        "@app.get(\"/download-report\")\n",
        "def download_report():\n",
        "    if CLEAN_DF is None:\n",
        "        return JSONResponse(status_code=400, content={\"error\": \"Run preprocess first\"})\n",
        "\n",
        "    filename = \"fitpulse_dashboard_report.pdf\"\n",
        "    doc = SimpleDocTemplate(filename, pagesize=A4)\n",
        "    styles = getSampleStyleSheet()\n",
        "    story = []\n",
        "\n",
        "    # ---------- TITLE ----------\n",
        "    story.append(Paragraph(\"<b>FitPulse Health Analytics Report</b>\", styles[\"Title\"]))\n",
        "    story.append(Spacer(1, 12))\n",
        "    story.append(Paragraph(\n",
        "        f\"Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\",\n",
        "        styles[\"Normal\"]\n",
        "    ))\n",
        "    story.append(Spacer(1, 20))\n",
        "\n",
        "    # ---------- OVERVIEW ----------\n",
        "    df = CLEAN_DF.copy()\n",
        "    overview_data = [\n",
        "        [\"Metric\", \"Value\"],\n",
        "        [\"Rows Loaded\", len(df)],\n",
        "        [\"Users\", df[\"user_id\"].nunique()],\n",
        "        [\"Days\", df[\"date\"].nunique()],\n",
        "        [\"Avg Heart Rate\", round(df[\"heart_rate\"].mean(), 1)],\n",
        "        [\"Start Date\", str(df[\"date\"].min().date())],\n",
        "        [\"End Date\", str(df[\"date\"].max().date())],\n",
        "    ]\n",
        "\n",
        "    overview_table = Table(overview_data)\n",
        "    overview_table.setStyle(TableStyle([\n",
        "        (\"BACKGROUND\", (0,0), (-1,0), colors.lightgrey),\n",
        "        (\"GRID\", (0,0), (-1,-1), 1, colors.black),\n",
        "        (\"FONT\", (0,0), (-1,0), \"Helvetica-Bold\"),\n",
        "    ]))\n",
        "\n",
        "    story.append(Paragraph(\"<b>Dataset Overview</b>\", styles[\"Heading2\"]))\n",
        "    story.append(Spacer(1, 10))\n",
        "    story.append(overview_table)\n",
        "    story.append(Spacer(1, 20))\n",
        "\n",
        "    # ---------- SAMPLE DATA ----------\n",
        "    story.append(Paragraph(\"<b>Sample Records</b>\", styles[\"Heading2\"]))\n",
        "    sample_table = df_to_table(df)\n",
        "    sample_table.setStyle(TableStyle([\n",
        "        (\"GRID\", (0,0), (-1,-1), 0.5, colors.grey),\n",
        "        (\"BACKGROUND\", (0,0), (-1,0), colors.whitesmoke),\n",
        "    ]))\n",
        "    story.append(sample_table)\n",
        "    story.append(Spacer(1, 20))\n",
        "\n",
        "    # ---------- ANOMALY SUMMARY ----------\n",
        "    if os.path.exists(\"anomaly_report.csv\"):\n",
        "        anom_df = pd.read_csv(\"anomaly_report.csv\")\n",
        "        story.append(Paragraph(\"<b>Anomaly Summary</b>\", styles[\"Heading2\"]))\n",
        "        anom_table = df_to_table(anom_df)\n",
        "        anom_table.setStyle(TableStyle([\n",
        "            (\"GRID\", (0,0), (-1,-1), 0.5, colors.grey),\n",
        "            (\"BACKGROUND\", (0,0), (-1,0), colors.lightgrey),\n",
        "        ]))\n",
        "        story.append(anom_table)\n",
        "        story.append(Spacer(1, 20))\n",
        "\n",
        "    # ---------- IMAGES ----------\n",
        "    story.append(Paragraph(\"<b>Visual Analytics</b>\", styles[\"Heading2\"]))\n",
        "    story.append(Spacer(1, 10))\n",
        "\n",
        "    image_files = (\n",
        "      glob.glob(\"prophet_heart_rate_*.png\") +\n",
        "      glob.glob(\"prophet_steps_*.png\") +\n",
        "      glob.glob(\"prophet_sleep_*.png\") +\n",
        "      [\"dbscan.png\", \"heart_rate_dist.png\", \"steps_dist.png\", \"sleep_dist.png\"]\n",
        "    )\n",
        "\n",
        "\n",
        "    for img in image_files:\n",
        "        if os.path.exists(img):\n",
        "            story.append(Image(img, width=400, height=220))\n",
        "            story.append(Spacer(1, 12))\n",
        "\n",
        "    # ---------- BUILD ----------\n",
        "    # ---------- RECOMMENDATIONS ----------\n",
        "    if os.path.exists(\"recommendations.csv\"):\n",
        "        rec_df = pd.read_csv(\"recommendations.csv\")\n",
        "        story.append(Paragraph(\"<b>Health Recommendations</b>\", styles[\"Heading2\"]))\n",
        "        rec_table = df_to_table(rec_df)\n",
        "        rec_table.setStyle(TableStyle([\n",
        "            (\"GRID\", (0,0), (-1,-1), 0.5, colors.grey),\n",
        "            (\"BACKGROUND\", (0,0), (-1,0), colors.lightgrey),\n",
        "        ]))\n",
        "        story.append(rec_table)\n",
        "        story.append(Spacer(1, 20))\n",
        "\n",
        "    doc.build(story)\n",
        "\n",
        "    return FileResponse(\n",
        "        filename,\n",
        "        media_type=\"application/pdf\",\n",
        "        filename=filename\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "@app.post(\"/llm-advice\")\n",
        "def llm_advice(\n",
        "    question: str = Body(...),\n",
        "    user_id: Optional[str] = Body(\"All\")\n",
        "):\n",
        "    global CLEAN_DF, ANOMALY_DF, RULE_RECOMMENDATIONS\n",
        "\n",
        "    if CLEAN_DF is None:\n",
        "        return {\"error\": \"No data available. Please preprocess data first.\"}\n",
        "\n",
        "    df = CLEAN_DF.copy()\n",
        "    df[\"user_id\"] = df[\"user_id\"].astype(str)\n",
        "\n",
        "    if user_id != \"All\":\n",
        "        df = df[df[\"user_id\"] == user_id]\n",
        "\n",
        "    if df.empty:\n",
        "        return {\"error\": \"No data available for selected user.\"}\n",
        "\n",
        "    summary_text = df.describe().to_string()\n",
        "\n",
        "    anomaly_text = \"\"\n",
        "    if ANOMALY_DF is not None and not ANOMALY_DF.empty:\n",
        "        adf = ANOMALY_DF.copy()\n",
        "        adf[\"user_id\"] = adf[\"user_id\"].astype(str)\n",
        "        if user_id != \"All\":\n",
        "            adf = adf[adf[\"user_id\"] == user_id]\n",
        "        anomaly_text = adf.head(20).to_string()\n",
        "\n",
        "    rules_text = \"\"\n",
        "    if RULE_RECOMMENDATIONS is not None and not RULE_RECOMMENDATIONS.empty:\n",
        "        rdf = RULE_RECOMMENDATIONS.copy()\n",
        "        rdf[\"user_id\"] = rdf[\"user_id\"].astype(str)\n",
        "        if user_id != \"All\":\n",
        "            rdf = rdf[rdf[\"user_id\"] == user_id]\n",
        "        rules_text = rdf.to_string()\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are a health analytics assistant.\n",
        "\n",
        "User-specific health data summary:\n",
        "{summary_text}\n",
        "\n",
        "Detected anomalies:\n",
        "{anomaly_text}\n",
        "\n",
        "Rule-based recommendations:\n",
        "{rules_text}\n",
        "\n",
        "User question:\n",
        "{question}\n",
        "\n",
        "Give clear, practical, non-medical wellness advice.\n",
        "\"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You provide general wellness advice, not medical diagnosis.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0.4,\n",
        "        max_tokens=300\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"answer\": response.choices[0].message.content.strip(),\n",
        "        \"user_id\": user_id\n",
        "    }"
      ],
      "metadata": {
        "id": "I14jE5jjv7W5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yUa7Fy5Yi63o"
      },
      "outputs": [],
      "source": [
        "import threading\n",
        "import uvicorn\n",
        "\n",
        "def run_backend():\n",
        "    uvicorn.run(\"backend:app\", host=\"0.0.0.0\", port=8003)\n",
        "\n",
        "threading.Thread(target=run_backend).start()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.kill()\n",
        "\n",
        "backend_url = ngrok.connect(8003)\n",
        "print(\"BACKEND URL:\", backend_url)"
      ],
      "metadata": {
        "id": "ZsKGrZo9jJSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ld19BpCmj6vk"
      },
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.kill()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p .streamlit"
      ],
      "metadata": {
        "id": "zVLzc69wlzqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile .streamlit/config.toml\n",
        "[theme]\n",
        "base=\"light\"\n",
        "primaryColor=\"#E63946\"\n",
        "backgroundColor=\"#F1FAEE\"\n",
        "secondaryBackgroundColor=\"#A8DADC\"\n",
        "textColor=\"#1D3557\""
      ],
      "metadata": {
        "id": "AibKm3_XmA3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import requests\n",
        "import io\n",
        "from datetime import datetime\n",
        "import plotly.express as px\n",
        "\n",
        "# ================= CONFIG =================\n",
        "BACKEND = \"http://localhost:8003\"\n",
        "HEADERS = {\"ngrok-skip-browser-warning\": \"true\"}\n",
        "\n",
        "st.set_page_config(\n",
        "    page_title=\"FitPulse Health Analytics\",\n",
        "    layout=\"wide\"\n",
        ")\n",
        "\n",
        "# ================= SESSION STATE =================\n",
        "if \"preprocess_done\" not in st.session_state:\n",
        "    st.session_state.preprocess_done = False\n",
        "\n",
        "if \"module2_done\" not in st.session_state:\n",
        "    st.session_state.module2_done = False\n",
        "\n",
        "# ================= API HELPERS =================\n",
        "def api_get(endpoint, raw=False):\n",
        "    r = requests.get(f\"{BACKEND}{endpoint}\", headers=HEADERS)\n",
        "    return r if raw else r.json()\n",
        "\n",
        "def api_post(endpoint, files=None):\n",
        "    return requests.post(f\"{BACKEND}{endpoint}\", files=files, headers=HEADERS).json()\n",
        "\n",
        "def api_post_json(endpoint, payload=None):\n",
        "    r = requests.post(\n",
        "        f\"{BACKEND}{endpoint}\",\n",
        "        json=payload,\n",
        "        headers=HEADERS\n",
        "    )\n",
        "    return r.json()\n",
        "\n",
        "\n",
        "# ================= COMMON FILTERS =================\n",
        "def sidebar_filters(metrics=True):\n",
        "    overview = api_get(\"/overview\")\n",
        "    users = [\"All\"]\n",
        "\n",
        "    try:\n",
        "        backend_users = overview.get(\"users_list\", [])\n",
        "        users += sorted([str(u) for u in backend_users])\n",
        "\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    user = st.sidebar.selectbox(\"Select User\", users)\n",
        "\n",
        "    try:\n",
        "        start = datetime.strptime(overview[\"start_date\"], \"%Y-%m-%d\")\n",
        "        end = datetime.strptime(overview[\"end_date\"], \"%Y-%m-%d\")\n",
        "    except:\n",
        "        start, end = datetime.today(), datetime.today()\n",
        "\n",
        "    dates = st.sidebar.date_input(\"Date Range\", [start, end])\n",
        "\n",
        "    metric = None\n",
        "    if metrics:\n",
        "        metric = st.sidebar.multiselect(\n",
        "            \"Select Metrics\",\n",
        "            [\"heart_rate\", \"steps\", \"sleep\"],\n",
        "            default=[\"heart_rate\", \"steps\", \"sleep\"]\n",
        "        )\n",
        "\n",
        "    return user, dates, metric\n",
        "\n",
        "# ================= SIDEBAR =================\n",
        "st.sidebar.title(\"FitPulse Controls\")\n",
        "\n",
        "page = st.sidebar.radio(\n",
        "    \"Navigation\",\n",
        "    [\n",
        "        \"1. Data Upload & Preprocessing\",\n",
        "        \"2. Feature Engineering & Anomalies\",\n",
        "        \"3. Trends\",\n",
        "        \"4. Anomalies\",\n",
        "        \"5. Distributions & DBSCAN\",\n",
        "        \"6. Downloads\"\n",
        "    ]\n",
        ")\n",
        "\n",
        "st.sidebar.divider()\n",
        "\n",
        "# ================= PAGE ROUTER =================\n",
        "if page == \"1. Data Upload & Preprocessing\":\n",
        "    st.title(\"FitPulse Health Analytics\")\n",
        "    with st.expander(\"Project Overview\", expanded=True):\n",
        "        st.markdown(\"\"\"\n",
        "**FitPulse** is an end-to-end health analytics system for wearable data.\n",
        "\n",
        "**Input Columns**\n",
        "- user_id\n",
        "- date\n",
        "- TotalSteps\n",
        "- avg_heart_rate\n",
        "- total_sleep_minutes\n",
        "\n",
        "**Outputs**\n",
        "- Cleaned dataset\n",
        "- Rolling health features\n",
        "- Anomalies & clustering\n",
        "- Interactive trends\n",
        "- CSV & PDF reports\n",
        "        \"\"\")\n",
        "\n",
        "    uploaded = st.file_uploader(\"Upload file\", type=[\"csv\", \"json\"])\n",
        "    if st.button(\"Run Preprocessing\"):\n",
        "        if not uploaded:\n",
        "            st.warning(\"Please upload a file first\")\n",
        "        else:\n",
        "            res = api_post(\"/preprocess\", files={\"file\": uploaded})\n",
        "            if res.get(\"status\") == \"success\":\n",
        "                st.success(\"Preprocessing completed\")\n",
        "                st.session_state.preprocess_done = True\n",
        "\n",
        "                ov = res[\"overview\"]\n",
        "                c1, c2, c3, c4 = st.columns(4)\n",
        "                c1.metric(\"Records\", ov[\"rows_loaded\"])\n",
        "                c2.metric(\"Users\", ov[\"users\"])\n",
        "                c3.metric(\"Days\", ov[\"days\"])\n",
        "                c4.metric(\"Avg HR\", ov[\"avg_hr\"])\n",
        "\n",
        "                st.dataframe(pd.DataFrame(res[\"preview\"]), use_container_width=True)\n",
        "            else:\n",
        "                st.error(res)\n",
        "\n",
        "elif page == \"2. Feature Engineering & Anomalies\":\n",
        "    st.title(\"Feature Engineering & Anomaly Detection\")\n",
        "    if not st.session_state.preprocess_done:\n",
        "        st.warning(\"Complete preprocessing first\")\n",
        "    else:\n",
        "        if st.button(\"Run Feature Engineering & Anomaly Detection\"):\n",
        "            res = api_post(\"/module2\")\n",
        "            if res.get(\"status\") == \"success\":\n",
        "                st.success(\"Module completed\")\n",
        "                st.session_state.module2_done = True\n",
        "                st.table(pd.DataFrame({\n",
        "                    \"Total Anomalies\": [res[\"total_anomalies\"]],\n",
        "                    \"Summary Rows\": [res[\"summary_rows\"]]\n",
        "                }))\n",
        "            else:\n",
        "                st.error(res)\n",
        "\n",
        "elif page == \"3. Trends\":\n",
        "    if not st.session_state.module2_done:\n",
        "        st.warning(\"Complete previous modules first\")\n",
        "    else:\n",
        "        st.title(\"Health Trends\")\n",
        "        user, _, metrics = sidebar_filters(metrics=True)\n",
        "\n",
        "        if not metrics:\n",
        "            st.warning(\"Select at least one metric\")\n",
        "        else:\n",
        "            for metric in metrics:\n",
        "                r = api_get(f\"/module3/prophet/{metric}?user_id={user}\", raw=True)\n",
        "                if r.status_code == 200:\n",
        "                    st.image(io.BytesIO(r.content), use_column_width=True)\n",
        "                else:\n",
        "                    st.error(r.json().get(\"error\", \"No data\"))\n",
        "\n",
        "elif page == \"4. Anomalies\":\n",
        "    if not st.session_state.module2_done:\n",
        "        st.warning(\"Complete previous modules first\")\n",
        "    else:\n",
        "        st.title(\"Anomaly Analysis\")\n",
        "        user, _, metrics = sidebar_filters(metrics=True)\n",
        "\n",
        "        summary = api_get(f\"/module3/summary?user_id={user}\")\n",
        "        df = pd.DataFrame(summary[\"summary\"].items(), columns=[\"Metric\", \"Count\"])\n",
        "\n",
        "        # ðŸ”¹ MAP UI METRICS â†’ BACKEND METRICS\n",
        "        metric_map = {\n",
        "            \"heart_rate\": [\"heart_rate_high\", \"heart_rate_low\"],\n",
        "            \"steps\": [\"no_steps\"],\n",
        "            \"sleep\": [\"sleep_abnormal\"]\n",
        "        }\n",
        "\n",
        "        selected_metrics = []\n",
        "        if metrics:\n",
        "            for m in metrics:\n",
        "                selected_metrics.extend(metric_map.get(m, []))\n",
        "\n",
        "        # FILTER SUMMARY\n",
        "        if selected_metrics:\n",
        "            df = df[df[\"Metric\"].isin(selected_metrics)]\n",
        "\n",
        "        fig = px.bar(df, x=\"Metric\", y=\"Count\", color=\"Metric\")\n",
        "        st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "        # ================= TABLE =================\n",
        "        table = api_get(\"/module3/anomaly-table\")\n",
        "        df_anom = pd.DataFrame(table[\"rows\"])\n",
        "\n",
        "        # ðŸ”¹ FIX USER TYPE MISMATCH\n",
        "        df_anom[\"user_id\"] = df_anom[\"user_id\"].astype(str)\n",
        "\n",
        "        if user != \"All\":\n",
        "            df_anom = df_anom[df_anom[\"user_id\"] == str(user)]\n",
        "\n",
        "        # FILTER TABLE BY METRICS\n",
        "        if selected_metrics:\n",
        "            df_anom = df_anom[df_anom[\"metric\"].isin(selected_metrics)]\n",
        "\n",
        "        st.dataframe(df_anom, use_container_width=True)\n",
        "\n",
        "elif page == \"5. Distributions & DBSCAN\":\n",
        "    if not st.session_state.module2_done:\n",
        "        st.warning(\"Complete previous modules first\")\n",
        "    else:\n",
        "        st.title(\"Distributions & Clustering\")\n",
        "        user, _, metrics = sidebar_filters(metrics=True)\n",
        "\n",
        "        for metric in metrics:\n",
        "            r = api_get(f\"/module3/distribution/{metric}?user_id={user}\", raw=True)\n",
        "            if r.status_code == 200:\n",
        "                st.image(io.BytesIO(r.content), caption=f\"{metric} distribution\", use_column_width=True)\n",
        "\n",
        "        if any(m in metrics for m in [\"heart_rate\", \"steps\", \"sleep\"]):\n",
        "            r = api_get(f\"/module3/dbscan?user_id={user}\", raw=True)\n",
        "            if r.status_code == 200:\n",
        "                st.image(io.BytesIO(r.content), caption=\"DBSCAN clustering\", use_column_width=True)\n",
        "\n",
        "elif page == \"6. Downloads\":\n",
        "    if not st.session_state.module2_done:\n",
        "        st.warning(\"Complete previous modules first\")\n",
        "    else:\n",
        "        st.title(\"Download Reports\")\n",
        "        user, _, _ = sidebar_filters(metrics=False)\n",
        "\n",
        "        r = api_get(\"/download-anomalies\", raw=True)\n",
        "        if r.status_code == 200:\n",
        "            st.download_button(\"Download Anomaly CSV\", r.content, \"anomaly_report.csv\")\n",
        "\n",
        "        r = api_get(\"/download-report\", raw=True)\n",
        "        if r.status_code == 200:\n",
        "            st.download_button(\"Download Full PDF Report\", r.content, \"fitpulse_dashboard_report.pdf\")\n",
        "\n",
        "        st.subheader(\"Ask Health Advisor (AI)\")\n",
        "        question = st.text_input(\"Ask a health-related question\")\n",
        "\n",
        "        if st.button(\"Ask AI\"):\n",
        "            res = api_post_json(\"/llm-advice\", {\"question\": question, \"user_id\": user})\n",
        "\n",
        "            if \"answer\" in res:\n",
        "                st.markdown(res[\"answer\"])\n",
        "            else:\n",
        "                st.error(res)\n",
        "\n",
        "st.caption(\"FitPulse | FastAPI Backend with Streamlit Frontend\")"
      ],
      "metadata": {
        "id": "-jNGlnLYOmxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py --server.port 8501 --server.address 0.0.0.0"
      ],
      "metadata": {
        "id": "z6Bz5WMJjOIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# Launch Streamlit via Ngrok\n",
        "# ===============================\n",
        "import threading, time\n",
        "def run_streamlit():\n",
        "    !streamlit run app.py --server.port 8501 --server.address 0.0.0.0\n",
        "threading.Thread(target=run_streamlit).start()\n",
        "time.sleep(5)\n",
        "streamlit_url = ngrok.connect(8501)\n",
        "print(\"Streamlit public URL:\", streamlit_url)"
      ],
      "metadata": {
        "id": "637cjqQhjVBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Kill any process running on port 8003 to resolve 'address already in use' error\n",
        "!lsof -i :8003 -t | xargs kill -9\n",
        "\n",
        "# Start uvicorn backend in the background\n",
        "!uvicorn backend:app --host 0.0.0.0 --port 8003 &"
      ],
      "metadata": {
        "id": "vyVLsEZ4kYuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QH1ZdgZMrti6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}